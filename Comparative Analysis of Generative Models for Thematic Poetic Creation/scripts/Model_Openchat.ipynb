{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce77ad9-848d-4b69-8fa4-e1b34653c87d",
   "metadata": {},
   "source": [
    "### Model Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015319e4-9597-4c7a-a8e3-7b1c571cbc1f",
   "metadata": {},
   "source": [
    "The script is loading the Openchat-3.5 7B model using Hugging Face's transformers library.\n",
    "\n",
    "* AutoTokenizer is used to load a pre-trained tokenizer\n",
    "* AutoModelForCausalLM loads the pre-trained language model for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92886278-794b-4938-b3d9-ce5bef666924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63a151dca564a91ab684185e86f42a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweet\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "C:\\Users\\sweet\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:590: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"openchat/openchat_3.5\")\n",
    "model1 = AutoModelForCausalLM.from_pretrained(\"openchat/openchat_3.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dcc316-e206-48a0-8fb4-484279ec0dcd",
   "metadata": {},
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24cec26e-b2d7-4598-a36a-75fff4b8d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import torch\n",
    "import collections\n",
    "from collections import Counter\n",
    "import math\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.util import ngrams\n",
    "import pronouncing\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff0cec-6e30-41b6-a51e-91dd2f23af77",
   "metadata": {},
   "source": [
    "### Dataset Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ba591a-96c5-4bc9-a1f9-22321cadf85c",
   "metadata": {},
   "source": [
    "The dataset is loaded from a CSV file containing prompts and generated poems. It includes all the poems generated by six models: Llama 3.2 3B Instruct Q8, Mistral 7B Instruct Q4, Gemma 2 2B Q4, QWEN2 7B Instruct Q4, Openchat-3.5 7B, and Code Ninja 7B Q4. \n",
    "\n",
    "Below are the prompts used to generate three poems:\n",
    "* Prompt 1: Write a Shakespearean sonnet about courage set on a battlefield with a determined tone. Use vivid imagery to convey strength and resilience.\n",
    "* Prompt 2: Write a Shakespearean sonnet about wonder set in outer space with an awe-filled tone. Use vivid imagery to convey mystery and discovery.\n",
    "* Prompt 3: Write a Shakespearean sonnet about loss set in an empty home with a somber tone. Use vivid imagery to convey grief and reflection.B Q4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3d77c6-a61a-4ea8-a481-0476568a6637",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"Model_gen_Poems.csv\"\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa64252d-ed0b-4346-9f47-46388051f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                                        Prompt/Model  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
      "\n",
      "                            Llama 3.2 3B Instruct Q8  \\\n",
      "0  Fair battlefield, where valorous hearts do lie...   \n",
      "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
      "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
      "\n",
      "                              Mistral 7B INSTRUCT Q4  \\\n",
      "0  Upon the field of battle, where chaos reigns,\\...   \n",
      "1  In the vast expanse of the cosmos, where stars...   \n",
      "2  In the empty home, where laughter once was hea...   \n",
      "\n",
      "                                       Gemma 2 2B Q4  \\\n",
      "0  Upon the field of strife, where blood doth sta...   \n",
      "1  Upon the velvet canvas of the night,\\nA millio...   \n",
      "2  The dust motes dance in sunbeams, pale and thi...   \n",
      "\n",
      "                                QWEN2 7B Instruct Q4  \\\n",
      "0  Amidst the clash of steel and blood, I stand u...   \n",
      "1  In the vast expanse of cosmic air, where stars...   \n",
      "2  In silent halls where shadows loom, \\nThe echo...   \n",
      "\n",
      "                                     Openchat-3.5 7B  \\\n",
      "0  Upon the field of strife, where metal meets,\\n...   \n",
      "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
      "2  Upon these hallowed walls, where echoes linger...   \n",
      "\n",
      "                                    Code Ninja 7B Q4  \n",
      "0  Upon the battlefield where fierce armies clash...  \n",
      "1  When first upon this boundless void I gazed,\\n...  \n",
      "2  When shadows eclipse the sun's bright ray,\\nAn...  \n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset Preview:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2fd93f1-1ca7-48a4-b206-1724e4b6ef82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Prompt/Model', 'Llama 3.2 3B Instruct Q8', 'Mistral 7B INSTRUCT Q4',\n",
      "       'Gemma 2 2B Q4', 'QWEN2 7B Instruct Q4', 'Openchat-3.5 7B',\n",
      "       'Code Ninja 7B Q4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f58ed5e-706e-4c69-8146-c8865456dec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Prompt/Model              3 non-null      object\n",
      " 1   Llama 3.2 3B Instruct Q8  3 non-null      object\n",
      " 2   Mistral 7B INSTRUCT Q4    3 non-null      object\n",
      " 3   Gemma 2 2B Q4             3 non-null      object\n",
      " 4   QWEN2 7B Instruct Q4      3 non-null      object\n",
      " 5   Openchat-3.5 7B           3 non-null      object\n",
      " 6   Code Ninja 7B Q4          3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 296.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4cec1-835d-4909-ba25-89443deee899",
   "metadata": {},
   "source": [
    "### Reference Poems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcffe60f-b65c-4118-b70d-75c7ea4a60fd",
   "metadata": {},
   "source": [
    "A list of reference poems is provided to evaluate the generated poem's quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86c572-7fe1-46e1-a299-d8ba256cd071",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 1 is taken from the website AllPoetry[https://allpoetry.com/poems/about/Courage]. The poem is titled The Brave Ones and is authored by Guilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3742b8-8e1f-40d5-86ae-139ab2b02d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt1 = (\n",
    "    \"The brave ones are the living\"\n",
    "    \"grabbing life with both hands\"\n",
    "    \"reckless adventures flying\"\n",
    "    \"with not a care where they land\"\n",
    "    \n",
    "    \"The meek ones merely exist\"\n",
    "    \"going unnoticed is their plan\"\n",
    "    \"perhaps they will perish\"\n",
    "    \"before they need to take a stand\"\n",
    "    \n",
    "    \"The brave ones believe\"\n",
    "    \"in more than what they see\"\n",
    "    \"the great unknown mystifies\"\n",
    "    \"and life is yet to be revealed\"\n",
    "    \n",
    "    \"The meek ones pity their lot\"\n",
    "    \"whatever they have is what they have got\"\n",
    "    \"there is nothing grand\"\n",
    "    \"in eating out of another’s hands\"\n",
    "    \n",
    "    \"Be bold, be brave and take a chance\"\n",
    "    \"a glorious failure is better than a lofty dream\"\n",
    "    \"never aspired for\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b72b2a-c7e0-4f9e-92fc-70811b4fcc46",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 2 is taken from the website [https://poemsplease.com/12-poems-reflecting-the-wonder-of-space-exploration/]. The poem is titled Boundless Skies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac553694-401f-4849-915c-608abe69cfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt2 = (\n",
    "    \"In the stillness of night, where silence reigns,\"\n",
    "    \"A canvas spreads, inked with ethereal gains.\"\n",
    "    \"Stars like diamonds twinkle, shimmering light,\"\n",
    "    \"Infinite stories held, ready for flight.\"\n",
    "    \"Comets trace paths, fiery trails that gleam,\"\n",
    "    \"While galaxies swirl in the vastest dream.\"\n",
    "    \"Cosmic whispers call, beckoning the brave,\"\n",
    "    \"To wander through wonders, the universe to save.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac3f18-fa6a-4368-9ce0-184d3df25e6f",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 3 is taken from the website [https://statics.teams.cdn.office.net/evergreen-assets/safelinks/1/atp-safelinks.html]. The poem is titled The Empty House and is authored by Walter de La Mare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b57a78ef-e849-4ada-9f9d-d22d4dfb8e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt3 = (\n",
    "    \"Whenever I walk to Suffern along the Erie track\"\n",
    "    \"I go by a poor old farmhouse with its shingles broken and black.\"\n",
    "    \"I suppose I've passed it a hundred times, but I always stop for a minute\"\n",
    "    \"And look at the house, the tragic house, the house with nobody in it.\"\n",
    "    \n",
    "    \"I never have seen a haunted house, but I hear there are such things;\"\n",
    "    \"That they hold the talk of spirits, their mirth and sorrowings.\"\n",
    "    \"I know this house isn't haunted, and I wish it were, I do;\"\n",
    "    \"For it wouldn't be so lonely if it had a ghost or two.\"\n",
    "    \n",
    "    \"This house on the road to Suffern needs a dozen panes of glass,\"\n",
    "    \"And somebody ought to weed the walk and take a scythe to the grass.\"\n",
    "    \"It needs new paint and shingles, and the vines should be trimmed and tied;\"\n",
    "    \"But what it needs the most of all is some people living inside.\"\n",
    "    \n",
    "    \"If I had a lot of money and all my debts were paid\"\n",
    "    \"I'd put a gang of men to work with brush and saw and spade.\"\n",
    "    \"I'd buy that place and fix it up the way it used to be\"\n",
    "    \"And I'd find some people who wanted a home and give it to them free.\"\n",
    "    \n",
    "    \"Now, a new house standing empty, with staring window and door,\"\n",
    "    \"Looks idle, perhaps, and foolish, like a hat on its block in the store.\"\n",
    "    \"But there's nothing mournful about it; it cannot be sad and lone\"\n",
    "    \"For the lack of something within it that it has never known.\"\n",
    "    \n",
    "    \"But a house that has done what a house should do,\"\n",
    "    \"a house that has sheltered life,\"\n",
    "    \"That has put its loving wooden arms around a man and his wife,\"\n",
    "    \"A house that has echoed a baby's laugh and held up his stumbling feet,\"\n",
    "    \"Is the saddest sight, when it's left alone, that ever your eyes could meet.\"\n",
    "    \n",
    "    \"So whenever I go to Suffern along the Erie track\"\n",
    "    \"I never go by the empty house without stopping and looking back,\"\n",
    "    \"Yet it hurts me to look at the crumbling roof and the shutters fallen apart,\"\n",
    "    \"For I can't help thinking the poor old house is a house with a broken heart.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "941000c8-6a1e-46b2-835e-bb1309c92823",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_poems = [referenced_poem_prompt1, referenced_poem_prompt2, referenced_poem_prompt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96b931a9-ecbf-4312-8d17-ad7ae57a892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Reference Poem\"] = reference_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845712f2-b68a-4c6c-b02a-e76785d474e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt/Model</th>\n",
       "      <th>Llama 3.2 3B Instruct Q8</th>\n",
       "      <th>Mistral 7B INSTRUCT Q4</th>\n",
       "      <th>Gemma 2 2B Q4</th>\n",
       "      <th>QWEN2 7B Instruct Q4</th>\n",
       "      <th>Openchat-3.5 7B</th>\n",
       "      <th>Code Ninja 7B Q4</th>\n",
       "      <th>Reference Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout courage s...</td>\n",
       "      <td>Fair battlefield, where valorous hearts do lie...</td>\n",
       "      <td>Upon the field of battle, where chaos reigns,\\...</td>\n",
       "      <td>Upon the field of strife, where blood doth sta...</td>\n",
       "      <td>Amidst the clash of steel and blood, I stand u...</td>\n",
       "      <td>Upon the field of strife, where metal meets,\\n...</td>\n",
       "      <td>Upon the battlefield where fierce armies clash...</td>\n",
       "      <td>The brave ones are the livinggrabbing life wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout wonder se...</td>\n",
       "      <td>Fairest cosmos, thou dost stretch thy might,\\n...</td>\n",
       "      <td>In the vast expanse of the cosmos, where stars...</td>\n",
       "      <td>Upon the velvet canvas of the night,\\nA millio...</td>\n",
       "      <td>In the vast expanse of cosmic air, where stars...</td>\n",
       "      <td>Upon the canvas of the boundless sky,\\nWhere d...</td>\n",
       "      <td>When first upon this boundless void I gazed,\\n...</td>\n",
       "      <td>In the stillness of night, where silence reign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout loss set ...</td>\n",
       "      <td>In vacant halls, where echoes whisper low,\\nA ...</td>\n",
       "      <td>In the empty home, where laughter once was hea...</td>\n",
       "      <td>The dust motes dance in sunbeams, pale and thi...</td>\n",
       "      <td>In silent halls where shadows loom, \\nThe echo...</td>\n",
       "      <td>Upon these hallowed walls, where echoes linger...</td>\n",
       "      <td>When shadows eclipse the sun's bright ray,\\nAn...</td>\n",
       "      <td>Whenever I walk to Suffern along the Erie trac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Prompt/Model  \\\n",
       "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
       "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
       "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
       "\n",
       "                            Llama 3.2 3B Instruct Q8  \\\n",
       "0  Fair battlefield, where valorous hearts do lie...   \n",
       "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
       "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
       "\n",
       "                              Mistral 7B INSTRUCT Q4  \\\n",
       "0  Upon the field of battle, where chaos reigns,\\...   \n",
       "1  In the vast expanse of the cosmos, where stars...   \n",
       "2  In the empty home, where laughter once was hea...   \n",
       "\n",
       "                                       Gemma 2 2B Q4  \\\n",
       "0  Upon the field of strife, where blood doth sta...   \n",
       "1  Upon the velvet canvas of the night,\\nA millio...   \n",
       "2  The dust motes dance in sunbeams, pale and thi...   \n",
       "\n",
       "                                QWEN2 7B Instruct Q4  \\\n",
       "0  Amidst the clash of steel and blood, I stand u...   \n",
       "1  In the vast expanse of cosmic air, where stars...   \n",
       "2  In silent halls where shadows loom, \\nThe echo...   \n",
       "\n",
       "                                     Openchat-3.5 7B  \\\n",
       "0  Upon the field of strife, where metal meets,\\n...   \n",
       "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
       "2  Upon these hallowed walls, where echoes linger...   \n",
       "\n",
       "                                    Code Ninja 7B Q4  \\\n",
       "0  Upon the battlefield where fierce armies clash...   \n",
       "1  When first upon this boundless void I gazed,\\n...   \n",
       "2  When shadows eclipse the sun's bright ray,\\nAn...   \n",
       "\n",
       "                                      Reference Poem  \n",
       "0  The brave ones are the livinggrabbing life wit...  \n",
       "1  In the stillness of night, where silence reign...  \n",
       "2  Whenever I walk to Suffern along the Erie trac...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf1d79-5e54-4233-9138-49907bf2c47a",
   "metadata": {},
   "source": [
    "### Fluency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0455fc-a5eb-41ed-b1e5-44d1483d1168",
   "metadata": {},
   "source": [
    "Evaluating fluency is important in poetry generation to ensure that the generated poems not only follow linguistic rules but also convey meaning smoothly. Several metrics can be used to assess the fluency of generated poetry:\n",
    "\n",
    "* METEOR (Metric for Evaluation of Translation with Explicit ORdering):\n",
    "Definition: METEOR is designed to address some of the shortcomings of BLEU, particularly by considering synonyms, stemming, and word order.\n",
    "Use: It evaluates the semantic and syntactic similarity between generated and reference text, which can be helpful for poetry generation.\n",
    "\n",
    "* BLEU (Bilingual Evaluation Understudy):\n",
    "Definition: BLEU is a metric commonly used in machine translation. It measures the precision of n-grams (contiguous sequences of n words) in the generated text against a reference text.\n",
    "Use: While it’s more commonly applied to translation tasks, it can be adapted to poetry evaluation by comparing n-grams between generated poems and reference poems.\n",
    "\n",
    "* Perplexity:\n",
    "Definition: Perplexity measures how well a model predicts the next word in a sequence. Lower perplexity indicates that the model is better at predicting text and is more \"certain\" in its predictions.\n",
    "Use: This can give an idea of how fluent or coherent the generated poem is, although it doesn't always align with creative quality.\n",
    "\n",
    "* Entropy:  \n",
    "Definition  : Entropy quantifies the average uncertainty or information content in the text. It measures the diversity or randomness in token distributions, such as characters or words, in the generated output. Higher entropy indicates more diverse text, while lower entropy suggests repetitive or predictable output.\n",
    "Use         : Entropy is valuable for evaluating poetry generation as it reflects the balance between creativity and structure. For poetry, moderate entropy often indicates well-crafted and varied text with coherent patterns, while extreme entropy values can signal overly repetitive or chaotic outputs. This metric helps compare models’ ability to produce diverse and engaging poems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d48fd89-4d68-4e6d-99cd-86908244ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Functions\n",
    "def bleu_score(reference, candidate):\n",
    "    return round(sentence_bleu([reference.split()], candidate.split()), 5)\n",
    "\n",
    "def meteor_score_func(reference, candidate):\n",
    "    # Tokenize both the reference and candidate\n",
    "    reference_tokens = reference.split()  # Tokenize the reference poem\n",
    "    candidate_tokens = candidate.split()  # Tokenize the generated poem\n",
    "    return round(meteor_score([reference_tokens], candidate_tokens), 5)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer1(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model1(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return round(torch.exp(loss).item(), 5)\n",
    "\n",
    "def calculate_entropy(text):\n",
    "    tokens = list(text)  # For word-level, use text.split()\n",
    "    \n",
    "    token_counts = Counter(tokens)\n",
    "    total_tokens = len(tokens)\n",
    "    \n",
    "    probabilities = [count / total_tokens for count in token_counts.values()]\n",
    "    \n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return round(entropy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7df063-17ee-4105-a511-3622528e885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model column to evaluate\n",
    "model_name_to_evaluate = \"Openchat-3.5 7B\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178c5648-af46-4c87-b949-3eae3675b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sweet\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sweet\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\sweet\\AppData\\Roaming\\Python\\Python38\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Openchat-3.5 7B\n",
      "                                              Prompt  BLEU   METEOR  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   0.0  0.10579   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   0.0  0.14953   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   0.0  0.08767   \n",
      "\n",
      "   Perplexity  Entropy  \n",
      "0     5.50861  4.32325  \n",
      "1     4.63650  4.43684  \n",
      "2     4.04432  4.40233  \n",
      "\n",
      "Average Entropy: 4.3875\n",
      "\n",
      "Average Perplexity: 4.7298\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Scores\n",
    "results = []\n",
    "for index, row in data.iterrows():\n",
    "    prompt = row[\"Prompt/Model\"]\n",
    "    reference_poem = row[\"Reference Poem\"]\n",
    "    generated_poem = row[model_name_to_evaluate]\n",
    "    \n",
    "    # Calculate scores\n",
    "    bleu = bleu_score(reference_poem, generated_poem)\n",
    "    meteor = meteor_score_func(reference_poem, generated_poem)\n",
    "    perplexity = calculate_perplexity(generated_poem)\n",
    "    entropy = calculate_entropy(generated_poem)\n",
    "    \n",
    "    # Append to results\n",
    "    results.append({\n",
    "        \"Prompt\": prompt,\n",
    "        \"BLEU\": bleu,\n",
    "        \"METEOR\": meteor,\n",
    "        \"Perplexity\": perplexity,\n",
    "        \"Entropy\": entropy\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate average entropy\n",
    "average_entropy = results_df[\"Entropy\"].mean()\n",
    "# Calculate average perplexity\n",
    "average_perplexity = results_df[\"Perplexity\"].mean()\n",
    "\n",
    "# Add model name to the title\n",
    "evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "\n",
    "# Display Results\n",
    "print(evaluation_title)\n",
    "print(results_df)\n",
    "\n",
    "# Display the average entropy\n",
    "print(f\"\\nAverage Entropy: {average_entropy:.4f}\")\n",
    "# Display the average perplexity\n",
    "print(f\"\\nAverage Perplexity: {average_perplexity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0f431-e4fc-4b22-a9b3-225d46be92c7",
   "metadata": {},
   "source": [
    "The table shows how well the Openchat-3.5 7B model performed in generating Shakespearean sonnets based on our prompts.\n",
    "\n",
    "1. BLEU: For all three prompts, the BLEU score is 0.0, meaning the generated sonnets don't closely match the reference sonnets in terms of exact word sequences. This suggests that the model doesn’t replicate the exact phrases or wording from the reference texts.\n",
    "\n",
    "2. METEOR: The METEOR scores range from 0.08767 to 0.14953, with the second prompt having the highest score. While these values are relatively low, they show that the model is still generating text that is somewhat meaningful, though it doesn't align very closely with the reference in terms of both meaning and structure.\n",
    "\n",
    "3. Perplexity: The perplexity scores range from 4.04432 to 5.50861, with the third prompt having the lowest score. This means the model is fairly good at predicting the next word, but there is still room for improvement in making the text more fluent and smooth.\n",
    "\n",
    "4. Entropy: The entropy values range from 4.32325 to 4.43684, indicating that the model is producing text with moderate diversity. The average entropy of 4.3875 suggests that the text has a balanced amount of variation, without being overly random or repetitive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a2e367-c2b2-4ef3-b68d-f1f02bc818e2",
   "metadata": {},
   "source": [
    "### Diversity and Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d19213d-47d9-46ac-9d2d-13748a81e2d4",
   "metadata": {},
   "source": [
    "In the context of poem generation, diversity and variety refer to the richness, uniqueness, and creativity of the generated text, which are critical for producing compelling, engaging, and original poetry.\n",
    "\n",
    "* Self-BLEU - Self-BLEU: Evaluates how much overlap exists between different samples generated by the same model.\n",
    "* Distinct n-grams: Measures the percentage of distinct n-grams in the generated text compared to the total n-grams. Higher distinctness means more diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7726e37e-131e-4805-88c1-6418eccc0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-BLEU Score\n",
    "def self_bleu(generated_texts, n=1):\n",
    "    all_ngrams = []\n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        all_ngrams.append(collections.Counter(ngrams_list))\n",
    "    \n",
    "    # Compute Self-BLEU score\n",
    "    score = 0\n",
    "    for i, counter in enumerate(all_ngrams):\n",
    "        others = all_ngrams[:i] + all_ngrams[i+1:]  # All other generated poems except the current one\n",
    "        union_ngrams = collections.Counter()\n",
    "        for other in others:\n",
    "            union_ngrams.update(other)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if sum(union_ngrams.values()) > 0:\n",
    "            overlap = sum(min(count, union_ngrams[gram]) for gram, count in counter.items())\n",
    "            score += overlap / sum(union_ngrams.values())\n",
    "    \n",
    "    return score / len(generated_texts) if len(generated_texts) > 1 else 0\n",
    "\n",
    "# Distinct-N Score\n",
    "def distinct_n(generated_texts, n=2):\n",
    "    ngrams_set = set()\n",
    "    total_ngrams = 0\n",
    "    \n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        ngrams_set.update(ngrams_list)  # Add n-grams to the set\n",
    "        total_ngrams += len(ngrams_list)\n",
    "    \n",
    "    return len(ngrams_set) / total_ngrams if total_ngrams > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a0fa33f-2586-4396-9d99-a909454d916d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Openchat-3.5 7B\n",
      "             Model                                             Prompt  \\\n",
      "0  Openchat-3.5 7B  Write a Shakespearean sonnet \\nabout courage s...   \n",
      "1  Openchat-3.5 7B  Write a Shakespearean sonnet \\nabout wonder se...   \n",
      "2  Openchat-3.5 7B  Write a Shakespearean sonnet \\nabout loss set ...   \n",
      "\n",
      "   Self-BLEU (n=1)  Distinct-2  \n",
      "0          0.16538     0.98295  \n",
      "1          0.16538     0.98295  \n",
      "2          0.16538     0.98295  \n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate Self-BLEU and Distinct-N for a model\n",
    "def evaluate_model_metrics(data, model_name_to_evaluate):\n",
    "    results = []\n",
    "\n",
    "    # Collect all poems generated by the same model across different prompts\n",
    "    generated_poems = data[model_name_to_evaluate].tolist()\n",
    "\n",
    "    # Calculate Self-BLEU and Distinct-N for the poems generated by the model\n",
    "    self_bleu_score = self_bleu(generated_poems, n=1)  # For unigrams (Self-BLEU n=1)\n",
    "    distinct_2_score = distinct_n(generated_poems, n=2)  # For distinct-2 (bigrams)\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row[\"Prompt/Model\"]\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name_to_evaluate,\n",
    "            \"Prompt\": prompt,\n",
    "            \"Self-BLEU (n=1)\": round(self_bleu_score, 5),\n",
    "            \"Distinct-2\": round(distinct_2_score, 5)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "    \n",
    "    print(evaluation_title)\n",
    "    print(results_df)\n",
    "\n",
    "model_name_to_evaluate = \"Openchat-3.5 7B\"\n",
    "evaluate_model_metrics(data, model_name_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348167b3-cf34-40c1-9d45-39de41dc7855",
   "metadata": {},
   "source": [
    "The evaluation results for the model Openchat-3.5 7B show that the model generates diverse and original poetry, with minimal repetition of words and a high degree of creativity:\n",
    "\n",
    "1. Self-BLEU - A low Self-BLEU score (0.16538) means that the different poems generated by the model don't share many common unigrams (individual words). This suggests the model isn't using the same words over and over, which shows that the poems are diverse in their word choice.\n",
    "2. Distinct-2 - A high Distinct-2 score (0.98295) indicates that most of the word pairs (bigrams) in the generated poems are unique. This shows that the model is good at creating varied and creative combinations of words, contributing to the originality of its output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eae396-ea57-4ac5-be6b-70563a86713a",
   "metadata": {},
   "source": [
    "### Poetic Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37b01d9-db47-4722-9cdb-177a8a86944b",
   "metadata": {},
   "source": [
    "The script evaluates the rhyming scheme of the generated poems.\n",
    "\n",
    "* Rhyming Scheme - The rhyming scheme refers to the pattern of rhymes at the end of each line in the poem.\n",
    "* Syllable Count - This step focuses on counting the syllables in each line of the poem. In structured poetry like sonnets, the number of syllables per line is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c3e75-e862-47e0-b4fb-21f2f9926bd8",
   "metadata": {},
   "source": [
    "#### Cleaning the sonnet and storing as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ddd596f-11c4-4954-8b62-b201ead3051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1:\n",
      "  Original Poem: Upon the field of strife, where metal meets,\n",
      "And fierce contention holds its bitter breath,\n",
      "There courage stands, a lion's heart it beats,\n",
      "In soldiers' bosoms, 'gainst all odds they wrench.\n",
      "\n",
      "With every step that falls upon the earth,\n",
      "A resounding echo of resolve doth rise,\n",
      "As brave hearts march to meet their mortal worth,\n",
      "And face the specter of eternity with eyes.\n",
      "\n",
      "Through smoke and fire, through noise and clashing steel,\n",
      "Their unwavering gaze doth pierce the fray,\n",
      "For they fight not for themselves, but for the real,\n",
      "To uphold the virtues that shall never sway.\n",
      "\n",
      "  Processed Lines: ['Upon the field of strife where metal meets', 'And fierce contention holds its bitter breath', 'There courage stands a lions heart it beats', 'In soldiers bosoms gainst all odds they wrench', 'With every step that falls upon the earth', 'A resounding echo of resolve doth rise', 'As brave hearts march to meet their mortal worth', 'And face the specter of eternity with eyes', 'Through smoke and fire through noise and clashing steel', 'Their unwavering gaze doth pierce the fray', 'For they fight not for themselves but for the real', 'To uphold the virtues that shall never sway']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Function to clean and split poems\n",
    "def process_poem(poem):\n",
    "    if isinstance(poem, str):  # Ensure the input is a string\n",
    "        lines = [\n",
    "            line.translate(str.maketrans('', '', string.punctuation))\n",
    "            for line in poem.strip().split('\\n') if line.strip()\n",
    "        ]\n",
    "        return poem, lines\n",
    "    else:\n",
    "        return None, []  # Handle NaN or non-string values\n",
    "\n",
    "\n",
    "# Filter the data for the selected model\n",
    "selected_poems = data[model_name_to_evaluate].head(3)  # Select the first 3 poems for the model\n",
    "\n",
    "# Process the selected poems and assign lines to variables\n",
    "poem1, lines1 = process_poem(selected_poems.iloc[0])\n",
    "poem2, lines2 = process_poem(selected_poems.iloc[1])\n",
    "poem3, lines3 = process_poem(selected_poems.iloc[2])\n",
    "\n",
    "# Print the processed lines for poem1\n",
    "print(\"Poem 1:\")\n",
    "print(f\"  Original Poem: {poem1}\")\n",
    "print(f\"  Processed Lines: {lines1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5c11ed-3c50-4836-8fb2-ecc7a2ad8374",
   "metadata": {},
   "source": [
    "A Shakespearean Sonnet is a 14 line poem which follows a consitent rhyme scheme pattern of ABAB CDCD EFEF GG and each line is 10 syllables long written in iambic pentameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418cb5f-6b18-4b29-a775-a95fcaab72ea",
   "metadata": {},
   "source": [
    "#### Finding the Rhyming Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76422546-f963-4cd4-aeff-b66382ead40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhyming Scheme for Poem 1: \n",
      "ABAC\n",
      "DEDE\n",
      "FGFG\n",
      "Rhyming Scheme for Poem 2: \n",
      "ABAB\n",
      "BCBC\n",
      "BDBE\n",
      "FF\n",
      "Rhyming Scheme for Poem 3: \n",
      "ABCD\n",
      "EFGH\n",
      "IJKL\n",
      "MNOP\n",
      "QRSI\n"
     ]
    }
   ],
   "source": [
    "poem_list = [lines1, lines2, lines3]\n",
    "\n",
    "def get_rhyming_scheme(lines):\n",
    "    # Extract the last word of each line\n",
    "    last_words = [line.split()[-1] for line in lines]\n",
    "    rhyme_dict = {}\n",
    "    scheme = []\n",
    "    current_letter = 'A'\n",
    "\n",
    "    for word in last_words:\n",
    "        rhymes = pronouncing.rhymes(word)\n",
    "        # Check if the word rhymes with any previously seen words\n",
    "        for key, letter in rhyme_dict.items():\n",
    "            if word in rhymes or key in rhymes:\n",
    "                scheme.append(letter)\n",
    "                break\n",
    "        else:\n",
    "            # Assign a new letter if no rhyming word is found\n",
    "            rhyme_dict[word] = current_letter\n",
    "            scheme.append(current_letter)\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "\n",
    "    rhyme_scheme = ''.join(scheme)\n",
    "    return '\\n'.join([rhyme_scheme[i:i+4] for i in range(0, len(rhyme_scheme), 4)])\n",
    "\n",
    "\n",
    "# Process each poem and print rhyming schemes\n",
    "for i, poem in enumerate(poem_list, 1):\n",
    "    rhyme_scheme = get_rhyming_scheme(poem)\n",
    "    print(f\"Rhyming Scheme for Poem {i}: \\n{rhyme_scheme}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d5fec4-559f-41de-bc3b-b124da185488",
   "metadata": {},
   "source": [
    "When we compare the rhyming schemes of these poems to a Shakespearean sonnet, we can see clear differences:\n",
    "\n",
    "1. Poem 1 has the rhyme scheme ABAC DEDE FGFG. This is not like a traditional Shakespearean sonnet, which follows a strict ABAB CDCD EFEF GG pattern. While it does have some repeated rhymes within stanzas, it doesn’t fully match the Shakespearean structure. \n",
    "\n",
    "2. Poem 2 uses the rhyme scheme ABAB BCBC BDBE FF. This is more complex and varied. The first two stanzas follow patterns that are somewhat similar to the Shakespearean style, but the third stanza switches things up. It ends with a rhyming couplet (FF), which is closer to the Shakespearean sonnet’s typical ending. However, the poem still doesn’t fully match the traditional structure due to the changing rhyme patterns in the middle.\n",
    "\n",
    "3. Poem 3 has a completely different rhyme scheme: ABCD EFGH IJKL MNOP QRSI. This one doesn’t repeat any rhymes across the stanzas, making it very free-form. There’s no recognizable pattern like ABAB or CDCD, and it doesn’t have a rhyming couplet at the end. Poem 3 strays the furthest from the Shakespearean sonnet form, focusing on more creative and diverse rhyming choices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f2748-89c2-4db9-838e-3d7ce29d6871",
   "metadata": {},
   "source": [
    "#### Finding the Syllable Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c69ea88-297f-4217-8f9c-cffa14c91256",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\sweet\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1 syllable counts: [10, 10, 10, 9, 10, 11, 10, 12, 10, 10, 11, 11]\n",
      "Poem 2 syllable counts: [10, 10, 10, 10, 10, 10, 9, 11, 10, 10, 10, 11, 10, 11]\n",
      "Poem 3 syllable counts: [11, 10, 10, 10, 10, 10, 10, 9, 11, 10, 11, 10, 10, 10, 10, 10, 10, 11, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"cmudict\")\n",
    "cmu_dict = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "    \"\"\"\n",
    "    Count syllables for a given word using the CMU Pronouncing Dictionary.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    if word in cmu_dict:\n",
    "        return min([len([y for y in x if y[-1].isdigit()]) for x in cmu_dict[word]])\n",
    "    return 1  \n",
    "\n",
    "def analyze_syllable_counts(poem):\n",
    "    \"\"\"\n",
    "    Analyze the syllable count for each line in the poem.\n",
    "    \"\"\"\n",
    "    syllable_counts = [sum(count_syllables(word) for word in re.findall(r'\\w+', line)) for line in poem]\n",
    "    return syllable_counts\n",
    "\n",
    "all_syllable_counts = [analyze_syllable_counts(poem) for poem in poem_list]\n",
    "\n",
    "for idx, syllable_count in enumerate(all_syllable_counts):\n",
    "    print(f\"Poem {idx + 1} syllable counts: {syllable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7200761f-5253-4500-9819-5d8cc9cd7011",
   "metadata": {},
   "source": [
    "The syllable counts for each poem show how they differ from the traditional structure of a Shakespearean sonnet, which typically has 14 lines, each with 10 syllables in iambic pentameter:\n",
    "\n",
    "1. Poem 1: The syllable counts range from 9 to 12 syllables per line, with most lines having 10 or 11 syllables. However, lines 4 (9 syllables) and 8 (12 syllables) stand out as exceptions. This variation suggests that the poem doesn't fully follow the typical 10-syllable pattern of iambic pentameter.\n",
    "\n",
    "2. Poem 2: Most of Poem 2's lines have 10 syllables, staying fairly close to the traditional structure. However, line 7 has 9 syllables, and lines 8 and 14 have 11 syllables. These small variations indicate that while the poem is mostly consistent, it still doesn't strictly stick to the 10-syllable rule.\n",
    "\n",
    "3. Poem 3: Poem 3 has a broader range of syllable counts, varying from 9 to 12 syllables per line. The inconsistencies, such as line 8 with 9 syllables and line 9 with 11 syllables, make the poem feel more free-flowing and less structured than a traditional Shakespearean sonnet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
