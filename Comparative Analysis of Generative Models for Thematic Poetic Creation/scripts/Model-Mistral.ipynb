{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed363203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Provide your Hugging Face token\n",
    "login(token=\"your token here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baefd5f5",
   "metadata": {},
   "source": [
    "### Model Loading:\n",
    "The script is loading the Mistral-7B-Instruct-v0.2 model using Hugging Face's transformers library.\n",
    "\n",
    "* AutoTokenizer is used to load a pre-trained tokenizer\n",
    "* AutoModelForCausalLM loads the pre-trained language model for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26eb5279",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:12<00:00, 24.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062afa05",
   "metadata": {},
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88135ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import torch\n",
    "import collections\n",
    "from collections import Counter\n",
    "import math\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.util import ngrams\n",
    "import pronouncing\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d045ba89",
   "metadata": {},
   "source": [
    "### Dataset Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1feda8",
   "metadata": {},
   "source": [
    "The dataset is loaded from a CSV file containing prompts and generated poems. It includes all the poems generated by six models: Llama 3.2 3B Instruct Q8, Mistral 7B Instruct Q4, Gemma 2 2B Q4, QWEN2 7B Instruct Q4, Openchat-3.5 7B, and Code Ninja 7B Q4. \n",
    "\n",
    "Below are the prompts used to generate three poems:\n",
    "* Prompt 1: Write a Shakespearean sonnet about courage set on a battlefield with a determined tone. Use vivid imagery to convey strength and resilience.\n",
    "* Prompt 2: Write a Shakespearean sonnet about wonder set in outer space with an awe-filled tone. Use vivid imagery to convey mystery and discovery.\n",
    "* Prompt 3: Write a Shakespearean sonnet about loss set in an empty home with a somber tone. Use vivid imagery to convey grief and reflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f608c331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                                        Prompt/Model  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
      "\n",
      "                            Llama 3.2 3B Instruct Q8  \\\n",
      "0  Fair battlefield, where valorous hearts do lie...   \n",
      "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
      "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
      "\n",
      "                              Mistral 7B INSTRUCT Q4  \\\n",
      "0  Upon the field of battle, where chaos reigns,\\...   \n",
      "1  In the vast expanse of the cosmos, where stars...   \n",
      "2  In the empty home, where laughter once was hea...   \n",
      "\n",
      "                                       Gemma 2 2B Q4  \\\n",
      "0  Upon the field of strife, where blood doth sta...   \n",
      "1  Upon the velvet canvas of the night,\\nA millio...   \n",
      "2  The dust motes dance in sunbeams, pale and thi...   \n",
      "\n",
      "                                QWEN2 7B Instruct Q4  \\\n",
      "0  Amidst the clash of steel and blood, I stand u...   \n",
      "1  In the vast expanse of cosmic air, where stars...   \n",
      "2  In silent halls where shadows loom, \\nThe echo...   \n",
      "\n",
      "                                     Openchat-3.5 7B  \\\n",
      "0  Upon the field of strife, where metal meets,\\n...   \n",
      "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
      "2  Upon these hallowed walls, where echoes linger...   \n",
      "\n",
      "                                    Code Ninja 7B Q4  \n",
      "0  Upon the battlefield where fierce armies clash...  \n",
      "1  When first upon this boundless void I gazed,\\n...  \n",
      "2  When shadows eclipse the sun's bright ray,\\nAn...  \n",
      "\n",
      "Column Names:\n",
      "Index(['Prompt/Model', 'Llama 3.2 3B Instruct Q8', 'Mistral 7B INSTRUCT Q4',\n",
      "       'Gemma 2 2B Q4', 'QWEN2 7B Instruct Q4', 'Openchat-3.5 7B',\n",
      "       'Code Ninja 7B Q4'],\n",
      "      dtype='object')\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Prompt/Model              3 non-null      object\n",
      " 1   Llama 3.2 3B Instruct Q8  3 non-null      object\n",
      " 2   Mistral 7B INSTRUCT Q4    3 non-null      object\n",
      " 3   Gemma 2 2B Q4             3 non-null      object\n",
      " 4   QWEN2 7B Instruct Q4      3 non-null      object\n",
      " 5   Openchat-3.5 7B           3 non-null      object\n",
      " 6   Code Ninja 7B Q4          3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 300.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Model_gen_Poems.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn Names:\")\n",
    "print(data.columns)\n",
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e60166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Prompt/Model', 'Llama 3.2 3B Instruct Q8', 'Mistral 7B INSTRUCT Q4',\n",
      "       'Gemma 2 2B Q4', 'QWEN2 7B Instruct Q4', 'Openchat-3.5 7B',\n",
      "       'Code Ninja 7B Q4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db265120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Prompt/Model              3 non-null      object\n",
      " 1   Llama 3.2 3B Instruct Q8  3 non-null      object\n",
      " 2   Mistral 7B INSTRUCT Q4    3 non-null      object\n",
      " 3   Gemma 2 2B Q4             3 non-null      object\n",
      " 4   QWEN2 7B Instruct Q4      3 non-null      object\n",
      " 5   Openchat-3.5 7B           3 non-null      object\n",
      " 6   Code Ninja 7B Q4          3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 300.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01fc96f",
   "metadata": {},
   "source": [
    "### Reference Poems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39398a1f",
   "metadata": {},
   "source": [
    "A list of reference poems is provided to evaluate the generated poem's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b6ead",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 1 is taken from the website AllPoetry[https://allpoetry.com/poems/about/Courage]. The poem is titled The Brave Ones and is authored by Guilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14edef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt1 = (\n",
    "    \"The brave ones are the living\"\n",
    "    \"grabbing life with both hands\"\n",
    "    \"reckless adventures flying\"\n",
    "    \"with not a care where they land\"\n",
    "    \n",
    "    \"The meek ones merely exist\"\n",
    "    \"going unnoticed is their plan\"\n",
    "    \"perhaps they will perish\"\n",
    "    \"before they need to take a stand\"\n",
    "    \n",
    "    \"The brave ones believe\"\n",
    "    \"in more than what they see\"\n",
    "    \"the great unknown mystifies\"\n",
    "    \"and life is yet to be revealed\"\n",
    "    \n",
    "    \"The meek ones pity their lot\"\n",
    "    \"whatever they have is what they have got\"\n",
    "    \"there is nothing grand\"\n",
    "    \"in eating out of another’s hands\"\n",
    "    \n",
    "    \"Be bold, be brave and take a chance\"\n",
    "    \"a glorious failure is better than a lofty dream\"\n",
    "    \"never aspired for\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe9d08",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 2 is taken from the website [https://poemsplease.com/12-poems-reflecting-the-wonder-of-space-exploration/]. The poem is titled Boundless Skies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ada82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt2 = (\n",
    "    \"In the stillness of night, where silence reigns,\"\n",
    "    \"A canvas spreads, inked with ethereal gains.\"\n",
    "    \"Stars like diamonds twinkle, shimmering light,\"\n",
    "    \"Infinite stories held, ready for flight.\"\n",
    "    \"Comets trace paths, fiery trails that gleam,\"\n",
    "    \"While galaxies swirl in the vastest dream.\"\n",
    "    \"Cosmic whispers call, beckoning the brave,\"\n",
    "    \"To wander through wonders, the universe to save.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145f035",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 3 is taken from the website [https://statics.teams.cdn.office.net/evergreen-assets/safelinks/1/atp-safelinks.html]. The poem is titled The Empty House and is authored by Walter de La Mare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea26bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt3 = (\n",
    "    \"Whenever I walk to Suffern along the Erie track\"\n",
    "    \"I go by a poor old farmhouse with its shingles broken and black.\"\n",
    "    \"I suppose I've passed it a hundred times, but I always stop for a minute\"\n",
    "    \"And look at the house, the tragic house, the house with nobody in it.\"\n",
    "    \n",
    "    \"I never have seen a haunted house, but I hear there are such things;\"\n",
    "    \"That they hold the talk of spirits, their mirth and sorrowings.\"\n",
    "    \"I know this house isn't haunted, and I wish it were, I do;\"\n",
    "    \"For it wouldn't be so lonely if it had a ghost or two.\"\n",
    "    \n",
    "    \"This house on the road to Suffern needs a dozen panes of glass,\"\n",
    "    \"And somebody ought to weed the walk and take a scythe to the grass.\"\n",
    "    \"It needs new paint and shingles, and the vines should be trimmed and tied;\"\n",
    "    \"But what it needs the most of all is some people living inside.\"\n",
    "    \n",
    "    \"If I had a lot of money and all my debts were paid\"\n",
    "    \"I'd put a gang of men to work with brush and saw and spade.\"\n",
    "    \"I'd buy that place and fix it up the way it used to be\"\n",
    "    \"And I'd find some people who wanted a home and give it to them free.\"\n",
    "    \n",
    "    \"Now, a new house standing empty, with staring window and door,\"\n",
    "    \"Looks idle, perhaps, and foolish, like a hat on its block in the store.\"\n",
    "    \"But there's nothing mournful about it; it cannot be sad and lone\"\n",
    "    \"For the lack of something within it that it has never known.\"\n",
    "    \n",
    "    \"But a house that has done what a house should do,\"\n",
    "    \"a house that has sheltered life,\"\n",
    "    \"That has put its loving wooden arms around a man and his wife,\"\n",
    "    \"A house that has echoed a baby's laugh and held up his stumbling feet,\"\n",
    "    \"Is the saddest sight, when it's left alone, that ever your eyes could meet.\"\n",
    "    \n",
    "    \"So whenever I go to Suffern along the Erie track\"\n",
    "    \"I never go by the empty house without stopping and looking back,\"\n",
    "    \"Yet it hurts me to look at the crumbling roof and the shutters fallen apart,\"\n",
    "    \"For I can't help thinking the poor old house is a house with a broken heart.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "769a7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_poems = [referenced_poem_prompt1, referenced_poem_prompt2, referenced_poem_prompt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb8805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Reference Poem\"] = reference_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f199beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt/Model</th>\n",
       "      <th>Llama 3.2 3B Instruct Q8</th>\n",
       "      <th>Mistral 7B INSTRUCT Q4</th>\n",
       "      <th>Gemma 2 2B Q4</th>\n",
       "      <th>QWEN2 7B Instruct Q4</th>\n",
       "      <th>Openchat-3.5 7B</th>\n",
       "      <th>Code Ninja 7B Q4</th>\n",
       "      <th>Reference Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout courage s...</td>\n",
       "      <td>Fair battlefield, where valorous hearts do lie...</td>\n",
       "      <td>Upon the field of battle, where chaos reigns,\\...</td>\n",
       "      <td>Upon the field of strife, where blood doth sta...</td>\n",
       "      <td>Amidst the clash of steel and blood, I stand u...</td>\n",
       "      <td>Upon the field of strife, where metal meets,\\n...</td>\n",
       "      <td>Upon the battlefield where fierce armies clash...</td>\n",
       "      <td>The brave ones are the livinggrabbing life wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout wonder se...</td>\n",
       "      <td>Fairest cosmos, thou dost stretch thy might,\\n...</td>\n",
       "      <td>In the vast expanse of the cosmos, where stars...</td>\n",
       "      <td>Upon the velvet canvas of the night,\\nA millio...</td>\n",
       "      <td>In the vast expanse of cosmic air, where stars...</td>\n",
       "      <td>Upon the canvas of the boundless sky,\\nWhere d...</td>\n",
       "      <td>When first upon this boundless void I gazed,\\n...</td>\n",
       "      <td>In the stillness of night, where silence reign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout loss set ...</td>\n",
       "      <td>In vacant halls, where echoes whisper low,\\nA ...</td>\n",
       "      <td>In the empty home, where laughter once was hea...</td>\n",
       "      <td>The dust motes dance in sunbeams, pale and thi...</td>\n",
       "      <td>In silent halls where shadows loom, \\nThe echo...</td>\n",
       "      <td>Upon these hallowed walls, where echoes linger...</td>\n",
       "      <td>When shadows eclipse the sun's bright ray,\\nAn...</td>\n",
       "      <td>Whenever I walk to Suffern along the Erie trac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Prompt/Model  \\\n",
       "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
       "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
       "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
       "\n",
       "                            Llama 3.2 3B Instruct Q8  \\\n",
       "0  Fair battlefield, where valorous hearts do lie...   \n",
       "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
       "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
       "\n",
       "                              Mistral 7B INSTRUCT Q4  \\\n",
       "0  Upon the field of battle, where chaos reigns,\\...   \n",
       "1  In the vast expanse of the cosmos, where stars...   \n",
       "2  In the empty home, where laughter once was hea...   \n",
       "\n",
       "                                       Gemma 2 2B Q4  \\\n",
       "0  Upon the field of strife, where blood doth sta...   \n",
       "1  Upon the velvet canvas of the night,\\nA millio...   \n",
       "2  The dust motes dance in sunbeams, pale and thi...   \n",
       "\n",
       "                                QWEN2 7B Instruct Q4  \\\n",
       "0  Amidst the clash of steel and blood, I stand u...   \n",
       "1  In the vast expanse of cosmic air, where stars...   \n",
       "2  In silent halls where shadows loom, \\nThe echo...   \n",
       "\n",
       "                                     Openchat-3.5 7B  \\\n",
       "0  Upon the field of strife, where metal meets,\\n...   \n",
       "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
       "2  Upon these hallowed walls, where echoes linger...   \n",
       "\n",
       "                                    Code Ninja 7B Q4  \\\n",
       "0  Upon the battlefield where fierce armies clash...   \n",
       "1  When first upon this boundless void I gazed,\\n...   \n",
       "2  When shadows eclipse the sun's bright ray,\\nAn...   \n",
       "\n",
       "                                      Reference Poem  \n",
       "0  The brave ones are the livinggrabbing life wit...  \n",
       "1  In the stillness of night, where silence reign...  \n",
       "2  Whenever I walk to Suffern along the Erie trac...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0f15d",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f8911",
   "metadata": {},
   "source": [
    "Evaluating fluency is important in poetry generation to ensure that the generated poems not only follow linguistic rules but also convey meaning smoothly. Several metrics can be used to assess the fluency of generated poetry:\n",
    "*   BLEU (Bilingual Evaluation Understudy):\n",
    "Definition  : BLEU is a metric commonly used in machine translation. It measures the precision of n-grams (contiguous sequences of n words) in the generated text against a reference text.\n",
    "Use         : While it’s more commonly applied to translation tasks, it can be adapted to poetry evaluation by comparing n-grams between generated poems and reference poems.\n",
    "\n",
    "*   METEOR (Metric for Evaluation of Translation with Explicit ORdering):\n",
    "Definition  : METEOR is designed to address some of the shortcomings of BLEU, particularly by considering synonyms, stemming, and word order.\n",
    "Use         : It evaluates the semantic and syntactic similarity between generated and reference text, which can be helpful for poetry generation.\n",
    "\n",
    "*   Perplexity:\n",
    "Definition  : Perplexity measures how well a model predicts the next word in a sequence. Lower perplexity indicates that the model is better at predicting text and is more \"certain\" in its predictions.\n",
    "Use         : This can give an idea of how fluent or coherent the generated poem is, although it doesn't always align with creative quality.\n",
    "\n",
    "*   Entropy:  \n",
    "Definition  : Entropy quantifies the average uncertainty or information content in the text. It measures the diversity or randomness in token distributions, such as characters or words, in the generated output. Higher entropy indicates more diverse text, while lower entropy suggests repetitive or predictable output.\n",
    "Use         : Entropy is valuable for evaluating poetry generation as it reflects the balance between creativity and structure. For poetry, moderate entropy often indicates well-crafted and varied text with coherent patterns, while extreme entropy values can signal overly repetitive or chaotic outputs. This metric helps compare models’ ability to produce diverse and engaging poems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd909156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Functions\n",
    "def bleu_score(reference, candidate):\n",
    "    return round(sentence_bleu([reference.split()], candidate.split()), 5)\n",
    "\n",
    "def meteor_score_func(reference, candidate):\n",
    "    # Tokenize both the reference and candidate\n",
    "    reference_tokens = reference.split()  \n",
    "    candidate_tokens = candidate.split()  \n",
    "    return round(meteor_score([reference_tokens], candidate_tokens), 5)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return round(torch.exp(loss).item(), 5)\n",
    "\n",
    "def calculate_entropy(text):\n",
    "    tokens = list(text)  \n",
    "    \n",
    "    token_counts = Counter(tokens)\n",
    "    total_tokens = len(tokens)\n",
    "    \n",
    "    probabilities = [count / total_tokens for count in token_counts.values()]\n",
    "    \n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return round(entropy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1816edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model column to evaluate\n",
    "model_name_to_evaluate = \"Mistral 7B INSTRUCT Q4\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a629b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Mistral 7B INSTRUCT Q4\n",
      "                                              Prompt  BLEU   METEOR  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   0.0  0.06486   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   0.0  0.19382   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   0.0  0.08349   \n",
      "\n",
      "   Perplexity  Entropy  \n",
      "0     2.95177  4.39219  \n",
      "1     3.01616  4.38685  \n",
      "2     2.66690  4.31930  \n",
      "\n",
      "Average Entropy: 4.3661\n",
      "\n",
      "Average Perplexity: 2.8783\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Scores\n",
    "results = []\n",
    "for index, row in data.iterrows():\n",
    "    prompt = row[\"Prompt/Model\"]\n",
    "    reference_poem = row[\"Reference Poem\"]\n",
    "    generated_poem = row[model_name_to_evaluate]\n",
    "    \n",
    "    # Calculate scores\n",
    "    bleu = bleu_score(reference_poem, generated_poem)\n",
    "    meteor = meteor_score_func(reference_poem, generated_poem)\n",
    "    perplexity = calculate_perplexity(generated_poem)\n",
    "    entropy = calculate_entropy(generated_poem)\n",
    "    \n",
    "    # Append to results\n",
    "    results.append({\n",
    "        \"Prompt\": prompt,\n",
    "        \"BLEU\": bleu,\n",
    "        \"METEOR\": meteor,\n",
    "        \"Perplexity\": perplexity,\n",
    "        \"Entropy\": entropy  # Fixed key capitalization for clarity\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate average entropy\n",
    "average_entropy = results_df[\"Entropy\"].mean()\n",
    "average_perplexity = results_df[\"Perplexity\"].mean()\n",
    "\n",
    "# Add model name to the title\n",
    "evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "\n",
    "# Display Results\n",
    "print(evaluation_title)\n",
    "print(results_df)\n",
    "\n",
    "# Display the average entropy\n",
    "print(f\"\\nAverage Entropy: {average_entropy:.4f}\")\n",
    "print(f\"\\nAverage Perplexity: {average_perplexity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b0d250",
   "metadata": {},
   "source": [
    "\n",
    "1. **BLEU**: This metric is 0.0 for all three poems, indicating that there is no repetition in the generated text. It suggests that the model has created highly unique text for each prompt without producing identical outputs.\n",
    "\n",
    "2. **METEOR**:METEOR scores measure the similarity between the generated text and reference text. A higher score suggests better alignment with reference human-written text. Poem 2 has a higher METEOR score(0.19382), implying it is more similar to the reference text than the others.\n",
    "\n",
    "3. **Perplexity**:Perplexity measures how well the model predicts the next word in a sequence. A lower perplexity indicates better performance. Poem 3 has the lowest perplexity, suggesting it is the easiest for the model to predict and thus has higher coherence or fluency. The average perplexity value of 2.8783 for the Mistral model indicates a relatively low level of uncertainty in its predictions, suggesting that the model generates more fluent and coherent text with fewer surprises.\n",
    "\n",
    "4. **Entropy**: Entropy reflects the uncertainty or randomness of the generated text. A higher value suggests more unpredictability. Poem 1 has the highest entropy, suggesting it is the most varied or unpredictable text among the three, while Poem 3 has slightly lower entropy, implying more predictable output.The average entropy value of 4.3661 for the  model indicates a moderate level of unpredictability in its predictions, suggesting that the model's generated text has some variability or uncertainty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75741b2",
   "metadata": {},
   "source": [
    "### Diversity and Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00b4879",
   "metadata": {},
   "source": [
    "In the context of poem generation, diversity and variety refer to the richness, uniqueness, and creativity of the generated text, which are critical for producing compelling, engaging, and original poetry.\n",
    "\n",
    "* Self-BLEU : Evaluates how much overlap exists between different samples generated by the same model.\n",
    "* Distinct n-grams: Measures the percentage of distinct n-grams in the generated text compared to the total n-grams. Higher distinctness means more diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44c8a4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1efd88bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-BLEU Score\n",
    "def self_bleu(generated_texts, n=1):\n",
    "    all_ngrams = []\n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        all_ngrams.append(collections.Counter(ngrams_list))\n",
    "    \n",
    "    # Compute Self-BLEU score\n",
    "    score = 0\n",
    "    for i, counter in enumerate(all_ngrams):\n",
    "        others = all_ngrams[:i] + all_ngrams[i+1:]  # All other generated poems except the current one\n",
    "        union_ngrams = collections.Counter()\n",
    "        for other in others:\n",
    "            union_ngrams.update(other)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if sum(union_ngrams.values()) > 0:\n",
    "            overlap = sum(min(count, union_ngrams[gram]) for gram, count in counter.items())\n",
    "            score += overlap / sum(union_ngrams.values())\n",
    "    \n",
    "    return score / len(generated_texts) if len(generated_texts) > 1 else 0\n",
    "\n",
    "# Distinct-N Score\n",
    "def distinct_n(generated_texts, n=2):\n",
    "    ngrams_set = set()\n",
    "    total_ngrams = 0\n",
    "    \n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        ngrams_set.update(ngrams_list)  # Add n-grams to the set\n",
    "        total_ngrams += len(ngrams_list)\n",
    "    \n",
    "    return len(ngrams_set) / total_ngrams if total_ngrams > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06608b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Mistral 7B INSTRUCT Q4\n",
      "                    Model                                             Prompt  \\\n",
      "0  Mistral 7B INSTRUCT Q4  Write a Shakespearean sonnet \\nabout courage s...   \n",
      "1  Mistral 7B INSTRUCT Q4  Write a Shakespearean sonnet \\nabout wonder se...   \n",
      "2  Mistral 7B INSTRUCT Q4  Write a Shakespearean sonnet \\nabout loss set ...   \n",
      "\n",
      "   Self-BLEU (n=1)  Distinct-2  \n",
      "0          0.20741     0.74734  \n",
      "1          0.20741     0.74734  \n",
      "2          0.20741     0.74734  \n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate Self-BLEU and Distinct-N for a model\n",
    "def evaluate_model_metrics(data, model_name_to_evaluate):\n",
    "    results = []\n",
    "\n",
    "    # Collect all poems generated by the same model across different prompts\n",
    "    generated_poems = data[model_name_to_evaluate].tolist()\n",
    "\n",
    "    # Calculate Self-BLEU and Distinct-N for the poems generated by the model\n",
    "    self_bleu_score = self_bleu(generated_poems, n=1)  # For unigrams (Self-BLEU n=1)\n",
    "    distinct_2_score = distinct_n(generated_poems, n=2)  # For distinct-2 (bigrams)\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row[\"Prompt/Model\"]\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name_to_evaluate,\n",
    "            \"Prompt\": prompt,\n",
    "            \"Self-BLEU (n=1)\": round(self_bleu_score, 5),\n",
    "            \"Distinct-2\": round(distinct_2_score, 5)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "    \n",
    "    print(evaluation_title)\n",
    "    print(results_df)\n",
    "\n",
    "# Example usage\n",
    "model_name_to_evaluate = \"Mistral 7B INSTRUCT Q4\"  \n",
    "evaluate_model_metrics(data, model_name_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de28261e",
   "metadata": {},
   "source": [
    "\n",
    "1. **Self-BLEU**: \n",
    "   - The Self-BLEU score for all three prompts is **0.20741**. This metric measures the uniqueness of the generated text by comparing it to other parts of the generated text. A score of 0.20741 suggests moderate repetition, meaning the model does not excessively repeat itself but may still reuse some structures or phrases across different outputs.\n",
    "\n",
    "2. **Distinct-2**: \n",
    "   - The **Distinct-2** score is **0.74734** for all three prompts. This metric evaluates the lexical diversity of the generated text by considering the proportion of unique 2-grams (pairs of consecutive words) in the output. A higher score indicates more varied output. In this case, the score of 0.74734 shows that the model generates fairly diverse text with a good amount of unique word pairs, contributing to more varied and less repetitive outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597fdf68",
   "metadata": {},
   "source": [
    "### Cleaning the sonnet and storing as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b4c3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1:\n",
      "  Original Poem: Upon the field of battle, where chaos reigns,\n",
      "Steps forth a figure, with courage unstained.\n",
      "A warrior, a hero, a beacon of might,\n",
      "Against the darkness, he stands in the fight.\n",
      "\n",
      "His eyes, they glimmer, with a flame so bright,\n",
      "A symbol of hope, a beacon of light.\n",
      "His spirit unbroken, his heart unbowed,\n",
      "He marches on, with courage unstowed.\n",
      "\n",
      "The bullets fly, the swords clash, the drums beat,\n",
      "But he remains undaunted, his courage complete.\n",
      "He fights for freedom, for justice, for right,\n",
      "A champion of hope, a symbol of light.\n",
      "\n",
      "In the midst of the chaos, he stands tall,\n",
      "His courage, his strength, his unyielding call.\n",
      "A symbol of resilience, of strength untold,\n",
      "A hero, a warrior, a true guardian of gold.\n",
      "\n",
      "  Processed Lines: ['Upon the field of battle where chaos reigns', 'Steps forth a figure with courage unstained', 'A warrior a hero a beacon of might', 'Against the darkness he stands in the fight', 'His eyes they glimmer with a flame so bright', 'A symbol of hope a beacon of light', 'His spirit unbroken his heart unbowed', 'He marches on with courage unstowed', 'The bullets fly the swords clash the drums beat', 'But he remains undaunted his courage complete', 'He fights for freedom for justice for right', 'A champion of hope a symbol of light', 'In the midst of the chaos he stands tall', 'His courage his strength his unyielding call', 'A symbol of resilience of strength untold', 'A hero a warrior a true guardian of gold']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Function to clean and split poems\n",
    "def process_poem(poem):\n",
    "    if isinstance(poem, str):  # Ensure the input is a string\n",
    "        lines = [\n",
    "            line.translate(str.maketrans('', '', string.punctuation))\n",
    "            for line in poem.strip().split('\\n') if line.strip()\n",
    "        ]\n",
    "        return poem, lines\n",
    "    else:\n",
    "        return None, []  # Handle NaN or non-string values\n",
    "\n",
    "\n",
    "# Filter the data for the selected model\n",
    "selected_poems = data[model_name_to_evaluate].head(3)  # Select the first 3 poems for the model\n",
    "\n",
    "# Process the selected poems and assign lines to variables\n",
    "poem1, lines1 = process_poem(selected_poems.iloc[0])\n",
    "poem2, lines2 = process_poem(selected_poems.iloc[1])\n",
    "poem3, lines3 = process_poem(selected_poems.iloc[2])\n",
    "\n",
    "# Print the processed lines for poem1\n",
    "print(\"Poem 1:\")\n",
    "print(f\"  Original Poem: {poem1}\")\n",
    "print(f\"  Processed Lines: {lines1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4ecfb",
   "metadata": {},
   "source": [
    "### Poetic Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f85b0d",
   "metadata": {},
   "source": [
    "A Shakespearean Sonnet is a 14 line poem which follows a consitent rhyme scheme pattern of ABAB CDCD EFEF GG and each line is 10 syllables long written in iambic pentameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274169b5",
   "metadata": {},
   "source": [
    "#### Finding the Rhyming Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8ed1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhyming Scheme for Poem 1: \n",
      "ABCC\n",
      "CCDE\n",
      "FFCC\n",
      "GGHH\n",
      "Rhyming Scheme for Poem 2: \n",
      "AABC\n",
      "DEFF\n",
      "AAGG\n",
      "HH\n",
      "Rhyming Scheme for Poem 3: \n",
      "ABCC\n",
      "DDEE\n",
      "FGHH\n",
      "IJKK\n"
     ]
    }
   ],
   "source": [
    "import pronouncing\n",
    "\n",
    "poem_list = [lines1, lines2, lines3]\n",
    "\n",
    "def get_rhyming_scheme(lines):\n",
    "    # Extract the last word of each line\n",
    "    last_words = [line.split()[-1] for line in lines]\n",
    "    rhyme_dict = {}\n",
    "    scheme = []\n",
    "    current_letter = 'A'\n",
    "\n",
    "    for word in last_words:\n",
    "        rhymes = pronouncing.rhymes(word)\n",
    "        # Check if the word rhymes with any previously seen words\n",
    "        for key, letter in rhyme_dict.items():\n",
    "            if word in rhymes or key in rhymes:\n",
    "                scheme.append(letter)\n",
    "                break\n",
    "        else:\n",
    "            # Assign a new letter if no rhyming word is found\n",
    "            rhyme_dict[word] = current_letter\n",
    "            scheme.append(current_letter)\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "\n",
    "    rhyme_scheme = ''.join(scheme)\n",
    "    return '\\n'.join([rhyme_scheme[i:i+4] for i in range(0, len(rhyme_scheme), 4)])\n",
    "\n",
    "\n",
    "# Process each poem and print rhyming schemes\n",
    "for i, poem in enumerate(poem_list, 1):\n",
    "    rhyme_scheme = get_rhyming_scheme(poem)\n",
    "    print(f\"Rhyming Scheme for Poem {i}: \\n{rhyme_scheme}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac33822",
   "metadata": {},
   "source": [
    "When we compare the rhyming schemes of these poems to a Shakespearean sonnet, we can see clear differences:\n",
    "\n",
    "**Poem 1**:Rhyming Scheme: ABCC CCDE FFCC GGHH\n",
    "It deviates from the Shakespearean sonnet by introducing repeated rhymes (CC and FFCC) within its structure, which does not follow the alternating pattern of a Shakespearean sonnet.\n",
    "The poem ends with GGHH, where the last two lines introduce an additional rhyme (HH), deviating from the traditional GG couplet.\n",
    "\n",
    "**Poem 2**:Rhyming Scheme: AABC DEFF AAGG HH\n",
    "It introduces a non-standard rhyme structure with AABC, which is not typical for a Shakespearean sonnet.\n",
    "It ends with HH, but the rhymes used in the rest of the poem (AABC, DEFF, AAGG) differ from the consistent alternating Stanzas of a Shakespearean sonnet.\n",
    "\n",
    "**Poem 3**:Rhyming Scheme: ABCC DDEE FGHH IJKK\n",
    "It shows a highly irregular rhyme pattern, with no alternating rhymes and new rhymes introduced in each section.\n",
    "It ends with IJKK, which does not conform to the Shakespearean sonnet's GG couplet, and contains no clear alternating Stanzas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e2193",
   "metadata": {},
   "source": [
    "#### Finding the Syllable Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e84398be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\pooji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1 syllable counts: [11, 10, 11, 10, 10, 10, 10, 8, 10, 12, 10, 11, 10, 10, 11, 13]\n",
      "Poem 2 syllable counts: [14, 14, 10, 9, 13, 12, 11, 10, 10, 10, 11, 11, 13, 15]\n",
      "Poem 3 syllable counts: [11, 8, 10, 14, 10, 11, 11, 11, 12, 10, 9, 10, 11, 8, 10, 14]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "nltk.download(\"cmudict\")\n",
    "cmu_dict = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "    \"\"\"\n",
    "    Count syllables for a given word using the CMU Pronouncing Dictionary.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    if word in cmu_dict:\n",
    "        return min([len([y for y in x if y[-1].isdigit()]) for x in cmu_dict[word]])\n",
    "    return 1  \n",
    "\n",
    "def analyze_syllable_counts(poem):\n",
    "    \"\"\"\n",
    "    Analyze the syllable count for each line in the poem.\n",
    "    \"\"\"\n",
    "    syllable_counts = [sum(count_syllables(word) for word in re.findall(r'\\w+', line)) for line in poem]\n",
    "    return syllable_counts\n",
    "\n",
    "all_syllable_counts = [analyze_syllable_counts(poem) for poem in poem_list]\n",
    "\n",
    "for idx, syllable_count in enumerate(all_syllable_counts):\n",
    "    print(f\"Poem {idx + 1} syllable counts: {syllable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afb2a94",
   "metadata": {},
   "source": [
    "The syllable counts across the three poems show significant variation, deviating from the traditional iambic pentameter structure of a Shakespearean sonnet (10 syllables per line).\n",
    "\n",
    "- **Poem 1**: Has a mix of 8-13 syllables per line, indicating some irregularity in rhythm.\n",
    "- **Poem 2**: Shows wider fluctuations (9-15 syllables), suggesting free-form and less structured rhythm.\n",
    "- **Poem 3**: Varies between 8-14 syllables, with some lines being notably shorter or longer, resulting in an irregular meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca5a365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
