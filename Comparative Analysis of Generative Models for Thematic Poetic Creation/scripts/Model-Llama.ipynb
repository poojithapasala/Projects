{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed363203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Provide your Hugging Face token\n",
    "login(token=\"your token here\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd6d07",
   "metadata": {},
   "source": [
    "### Model Loading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ce9319",
   "metadata": {},
   "source": [
    "The script is loading the Llama-3.2-3B-Instruct model using Hugging Face's transformers library.\n",
    "\n",
    "* AutoTokenizer is used to load a pre-trained tokenizer\n",
    "* AutoModelForCausalLM loads the pre-trained language model for text generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab46ea1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:53<00:00, 26.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")\n",
    "model     = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a76074",
   "metadata": {},
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062afa05",
   "metadata": {},
   "source": [
    "### Load Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88135ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import torch\n",
    "import collections\n",
    "from collections import Counter\n",
    "import math\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from nltk.util import ngrams\n",
    "import pronouncing\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d73d3",
   "metadata": {},
   "source": [
    "### Dataset Handling:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e386ad",
   "metadata": {},
   "source": [
    "The dataset is loaded from a CSV file containing prompts and generated poems. It includes all the poems generated by six models: Llama 3.2 3B Instruct Q8, Mistral 7B Instruct Q4, Gemma 2 2B Q4, QWEN2 7B Instruct Q4, Openchat-3.5 7B, and Code Ninja 7B Q4. \n",
    "\n",
    "Below are the prompts used to generate three poems:\n",
    "* Prompt 1: Write a Shakespearean sonnet about courage set on a battlefield with a determined tone. Use vivid imagery to convey strength and resilience.\n",
    "* Prompt 2: Write a Shakespearean sonnet about wonder set in outer space with an awe-filled tone. Use vivid imagery to convey mystery and discovery.\n",
    "* Prompt 3: Write a Shakespearean sonnet about loss set in an empty home with a somber tone. Use vivid imagery to convey grief and reflection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee65abac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Preview:\n",
      "                                        Prompt/Model  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
      "\n",
      "                            Llama 3.2 3B Instruct Q8  \\\n",
      "0  Fair battlefield, where valorous hearts do lie...   \n",
      "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
      "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
      "\n",
      "                              Mistral 7B INSTRUCT Q4  \\\n",
      "0  Upon the field of battle, where chaos reigns,\\...   \n",
      "1  In the vast expanse of the cosmos, where stars...   \n",
      "2  In the empty home, where laughter once was hea...   \n",
      "\n",
      "                                       Gemma 2 2B Q4  \\\n",
      "0  Upon the field of strife, where blood doth sta...   \n",
      "1  Upon the velvet canvas of the night,\\nA millio...   \n",
      "2  The dust motes dance in sunbeams, pale and thi...   \n",
      "\n",
      "                                QWEN2 7B Instruct Q4  \\\n",
      "0  Amidst the clash of steel and blood, I stand u...   \n",
      "1  In the vast expanse of cosmic air, where stars...   \n",
      "2  In silent halls where shadows loom, \\nThe echo...   \n",
      "\n",
      "                                     Openchat-3.5 7B  \\\n",
      "0  Upon the field of strife, where metal meets,\\n...   \n",
      "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
      "2  Upon these hallowed walls, where echoes linger...   \n",
      "\n",
      "                                    Code Ninja 7B Q4  \n",
      "0  Upon the battlefield where fierce armies clash...  \n",
      "1  When first upon this boundless void I gazed,\\n...  \n",
      "2  When shadows eclipse the sun's bright ray,\\nAn...  \n",
      "\n",
      "Column Names:\n",
      "Index(['Prompt/Model', 'Llama 3.2 3B Instruct Q8', 'Mistral 7B INSTRUCT Q4',\n",
      "       'Gemma 2 2B Q4', 'QWEN2 7B Instruct Q4', 'Openchat-3.5 7B',\n",
      "       'Code Ninja 7B Q4'],\n",
      "      dtype='object')\n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Prompt/Model              3 non-null      object\n",
      " 1   Llama 3.2 3B Instruct Q8  3 non-null      object\n",
      " 2   Mistral 7B INSTRUCT Q4    3 non-null      object\n",
      " 3   Gemma 2 2B Q4             3 non-null      object\n",
      " 4   QWEN2 7B Instruct Q4      3 non-null      object\n",
      " 5   Openchat-3.5 7B           3 non-null      object\n",
      " 6   Code Ninja 7B Q4          3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 300.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "file_path = \"Model_gen_Poems.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "print(\"Dataset Preview:\")\n",
    "print(data.head())\n",
    "print(\"\\nColumn Names:\")\n",
    "print(data.columns)\n",
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58b78f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['Prompt/Model', 'Llama 3.2 3B Instruct Q8', 'Mistral 7B INSTRUCT Q4',\n",
      "       'Gemma 2 2B Q4', 'QWEN2 7B Instruct Q4', 'Openchat-3.5 7B',\n",
      "       'Code Ninja 7B Q4'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nColumn Names:\")\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3dc9883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 7 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Prompt/Model              3 non-null      object\n",
      " 1   Llama 3.2 3B Instruct Q8  3 non-null      object\n",
      " 2   Mistral 7B INSTRUCT Q4    3 non-null      object\n",
      " 3   Gemma 2 2B Q4             3 non-null      object\n",
      " 4   QWEN2 7B Instruct Q4      3 non-null      object\n",
      " 5   Openchat-3.5 7B           3 non-null      object\n",
      " 6   Code Ninja 7B Q4          3 non-null      object\n",
      "dtypes: object(7)\n",
      "memory usage: 300.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01fc96f",
   "metadata": {},
   "source": [
    "### Reference Poems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878b62d",
   "metadata": {},
   "source": [
    "A list of reference poems is provided to evaluate the generated poem's quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454b6ead",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 1 is taken from the website AllPoetry[https://allpoetry.com/poems/about/Courage]. The poem is titled The Brave Ones and is authored by Guilty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14edef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt1 = (\n",
    "    \"The brave ones are the living\"\n",
    "    \"grabbing life with both hands\"\n",
    "    \"reckless adventures flying\"\n",
    "    \"with not a care where they land\"\n",
    "    \n",
    "    \"The meek ones merely exist\"\n",
    "    \"going unnoticed is their plan\"\n",
    "    \"perhaps they will perish\"\n",
    "    \"before they need to take a stand\"\n",
    "    \n",
    "    \"The brave ones believe\"\n",
    "    \"in more than what they see\"\n",
    "    \"the great unknown mystifies\"\n",
    "    \"and life is yet to be revealed\"\n",
    "    \n",
    "    \"The meek ones pity their lot\"\n",
    "    \"whatever they have is what they have got\"\n",
    "    \"there is nothing grand\"\n",
    "    \"in eating out of another’s hands\"\n",
    "    \n",
    "    \"Be bold, be brave and take a chance\"\n",
    "    \"a glorious failure is better than a lofty dream\"\n",
    "    \"never aspired for\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fe9d08",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 2 is taken from the website [https://poemsplease.com/12-poems-reflecting-the-wonder-of-space-exploration/]. The poem is titled Boundless Skies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ada82a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt2 = (\n",
    "    \"In the stillness of night, where silence reigns,\"\n",
    "    \"A canvas spreads, inked with ethereal gains.\"\n",
    "    \"Stars like diamonds twinkle, shimmering light,\"\n",
    "    \"Infinite stories held, ready for flight.\"\n",
    "    \"Comets trace paths, fiery trails that gleam,\"\n",
    "    \"While galaxies swirl in the vastest dream.\"\n",
    "    \"Cosmic whispers call, beckoning the brave,\"\n",
    "    \"To wander through wonders, the universe to save.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9145f035",
   "metadata": {},
   "source": [
    "The reference for the poem in prompt 3 is taken from the website [https://statics.teams.cdn.office.net/evergreen-assets/safelinks/1/atp-safelinks.html]. The poem is titled The Empty House and is authored by Walter de La Mare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea26bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "referenced_poem_prompt3 = (\n",
    "    \"Whenever I walk to Suffern along the Erie track\"\n",
    "    \"I go by a poor old farmhouse with its shingles broken and black.\"\n",
    "    \"I suppose I've passed it a hundred times, but I always stop for a minute\"\n",
    "    \"And look at the house, the tragic house, the house with nobody in it.\"\n",
    "    \n",
    "    \"I never have seen a haunted house, but I hear there are such things;\"\n",
    "    \"That they hold the talk of spirits, their mirth and sorrowings.\"\n",
    "    \"I know this house isn't haunted, and I wish it were, I do;\"\n",
    "    \"For it wouldn't be so lonely if it had a ghost or two.\"\n",
    "    \n",
    "    \"This house on the road to Suffern needs a dozen panes of glass,\"\n",
    "    \"And somebody ought to weed the walk and take a scythe to the grass.\"\n",
    "    \"It needs new paint and shingles, and the vines should be trimmed and tied;\"\n",
    "    \"But what it needs the most of all is some people living inside.\"\n",
    "    \n",
    "    \"If I had a lot of money and all my debts were paid\"\n",
    "    \"I'd put a gang of men to work with brush and saw and spade.\"\n",
    "    \"I'd buy that place and fix it up the way it used to be\"\n",
    "    \"And I'd find some people who wanted a home and give it to them free.\"\n",
    "    \n",
    "    \"Now, a new house standing empty, with staring window and door,\"\n",
    "    \"Looks idle, perhaps, and foolish, like a hat on its block in the store.\"\n",
    "    \"But there's nothing mournful about it; it cannot be sad and lone\"\n",
    "    \"For the lack of something within it that it has never known.\"\n",
    "    \n",
    "    \"But a house that has done what a house should do,\"\n",
    "    \"a house that has sheltered life,\"\n",
    "    \"That has put its loving wooden arms around a man and his wife,\"\n",
    "    \"A house that has echoed a baby's laugh and held up his stumbling feet,\"\n",
    "    \"Is the saddest sight, when it's left alone, that ever your eyes could meet.\"\n",
    "    \n",
    "    \"So whenever I go to Suffern along the Erie track\"\n",
    "    \"I never go by the empty house without stopping and looking back,\"\n",
    "    \"Yet it hurts me to look at the crumbling roof and the shutters fallen apart,\"\n",
    "    \"For I can't help thinking the poor old house is a house with a broken heart.\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "769a7492",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_poems = [referenced_poem_prompt1, referenced_poem_prompt2, referenced_poem_prompt3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fb8805d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for reference poems\n",
    "data[\"Reference Poem\"] = reference_poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f199beb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt/Model</th>\n",
       "      <th>Llama 3.2 3B Instruct Q8</th>\n",
       "      <th>Mistral 7B INSTRUCT Q4</th>\n",
       "      <th>Gemma 2 2B Q4</th>\n",
       "      <th>QWEN2 7B Instruct Q4</th>\n",
       "      <th>Openchat-3.5 7B</th>\n",
       "      <th>Code Ninja 7B Q4</th>\n",
       "      <th>Reference Poem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout courage s...</td>\n",
       "      <td>Fair battlefield, where valorous hearts do lie...</td>\n",
       "      <td>Upon the field of battle, where chaos reigns,\\...</td>\n",
       "      <td>Upon the field of strife, where blood doth sta...</td>\n",
       "      <td>Amidst the clash of steel and blood, I stand u...</td>\n",
       "      <td>Upon the field of strife, where metal meets,\\n...</td>\n",
       "      <td>Upon the battlefield where fierce armies clash...</td>\n",
       "      <td>The brave ones are the livinggrabbing life wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout wonder se...</td>\n",
       "      <td>Fairest cosmos, thou dost stretch thy might,\\n...</td>\n",
       "      <td>In the vast expanse of the cosmos, where stars...</td>\n",
       "      <td>Upon the velvet canvas of the night,\\nA millio...</td>\n",
       "      <td>In the vast expanse of cosmic air, where stars...</td>\n",
       "      <td>Upon the canvas of the boundless sky,\\nWhere d...</td>\n",
       "      <td>When first upon this boundless void I gazed,\\n...</td>\n",
       "      <td>In the stillness of night, where silence reign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a Shakespearean sonnet \\nabout loss set ...</td>\n",
       "      <td>In vacant halls, where echoes whisper low,\\nA ...</td>\n",
       "      <td>In the empty home, where laughter once was hea...</td>\n",
       "      <td>The dust motes dance in sunbeams, pale and thi...</td>\n",
       "      <td>In silent halls where shadows loom, \\nThe echo...</td>\n",
       "      <td>Upon these hallowed walls, where echoes linger...</td>\n",
       "      <td>When shadows eclipse the sun's bright ray,\\nAn...</td>\n",
       "      <td>Whenever I walk to Suffern along the Erie trac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Prompt/Model  \\\n",
       "0  Write a Shakespearean sonnet \\nabout courage s...   \n",
       "1  Write a Shakespearean sonnet \\nabout wonder se...   \n",
       "2  Write a Shakespearean sonnet \\nabout loss set ...   \n",
       "\n",
       "                            Llama 3.2 3B Instruct Q8  \\\n",
       "0  Fair battlefield, where valorous hearts do lie...   \n",
       "1  Fairest cosmos, thou dost stretch thy might,\\n...   \n",
       "2  In vacant halls, where echoes whisper low,\\nA ...   \n",
       "\n",
       "                              Mistral 7B INSTRUCT Q4  \\\n",
       "0  Upon the field of battle, where chaos reigns,\\...   \n",
       "1  In the vast expanse of the cosmos, where stars...   \n",
       "2  In the empty home, where laughter once was hea...   \n",
       "\n",
       "                                       Gemma 2 2B Q4  \\\n",
       "0  Upon the field of strife, where blood doth sta...   \n",
       "1  Upon the velvet canvas of the night,\\nA millio...   \n",
       "2  The dust motes dance in sunbeams, pale and thi...   \n",
       "\n",
       "                                QWEN2 7B Instruct Q4  \\\n",
       "0  Amidst the clash of steel and blood, I stand u...   \n",
       "1  In the vast expanse of cosmic air, where stars...   \n",
       "2  In silent halls where shadows loom, \\nThe echo...   \n",
       "\n",
       "                                     Openchat-3.5 7B  \\\n",
       "0  Upon the field of strife, where metal meets,\\n...   \n",
       "1  Upon the canvas of the boundless sky,\\nWhere d...   \n",
       "2  Upon these hallowed walls, where echoes linger...   \n",
       "\n",
       "                                    Code Ninja 7B Q4  \\\n",
       "0  Upon the battlefield where fierce armies clash...   \n",
       "1  When first upon this boundless void I gazed,\\n...   \n",
       "2  When shadows eclipse the sun's bright ray,\\nAn...   \n",
       "\n",
       "                                      Reference Poem  \n",
       "0  The brave ones are the livinggrabbing life wit...  \n",
       "1  In the stillness of night, where silence reign...  \n",
       "2  Whenever I walk to Suffern along the Erie trac...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0f15d",
   "metadata": {},
   "source": [
    "## Fluency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f8911",
   "metadata": {},
   "source": [
    "Evaluating fluency is important in poetry generation to ensure that the generated poems not only follow linguistic rules but also convey meaning smoothly. Several metrics can be used to assess the fluency of generated poetry:\n",
    "*   BLEU (Bilingual Evaluation Understudy):\n",
    "Definition  : BLEU is a metric commonly used in machine translation. It measures the precision of n-grams (contiguous sequences of n words) in the generated text against a reference text.\n",
    "Use         : While it’s more commonly applied to translation tasks, it can be adapted to poetry evaluation by comparing n-grams between generated poems and reference poems.\n",
    "\n",
    "*   METEOR (Metric for Evaluation of Translation with Explicit ORdering):\n",
    "Definition  : METEOR is designed to address some of the shortcomings of BLEU, particularly by considering synonyms, stemming, and word order.\n",
    "Use         : It evaluates the semantic and syntactic similarity between generated and reference text, which can be helpful for poetry generation.\n",
    "\n",
    "*   Perplexity:\n",
    "Definition  : Perplexity measures how well a model predicts the next word in a sequence. Lower perplexity indicates that the model is better at predicting text and is more \"certain\" in its predictions.\n",
    "Use         : This can give an idea of how fluent or coherent the generated poem is, although it doesn't always align with creative quality.\n",
    "\n",
    "*   Entropy:  \n",
    "Definition  : Entropy quantifies the average uncertainty or information content in the text. It measures the diversity or randomness in token distributions, such as characters or words, in the generated output. Higher entropy indicates more diverse text, while lower entropy suggests repetitive or predictable output.\n",
    "Use         : Entropy is valuable for evaluating poetry generation as it reflects the balance between creativity and structure. For poetry, moderate entropy often indicates well-crafted and varied text with coherent patterns, while extreme entropy values can signal overly repetitive or chaotic outputs. This metric helps compare models’ ability to produce diverse and engaging poems.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd909156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Functions\n",
    "def bleu_score(reference, candidate):\n",
    "    return round(sentence_bleu([reference.split()], candidate.split()), 5)\n",
    "\n",
    "def meteor_score_func(reference, candidate):\n",
    "    # Tokenize both the reference and candidate\n",
    "    reference_tokens = reference.split()  # Tokenize the reference poem\n",
    "    candidate_tokens = candidate.split()  # Tokenize the generated poem\n",
    "    return round(meteor_score([reference_tokens], candidate_tokens), 5)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "        loss = outputs.loss\n",
    "        return round(torch.exp(loss).item(), 5)\n",
    "\n",
    "def calculate_entropy(text):\n",
    "    tokens = list(text)  # For word-level, use text.split()\n",
    "    \n",
    "    token_counts = Counter(tokens)\n",
    "    total_tokens = len(tokens)\n",
    "    \n",
    "    probabilities = [count / total_tokens for count in token_counts.values()]\n",
    "    \n",
    "    entropy = -sum(p * math.log2(p) for p in probabilities)\n",
    "    return round(entropy, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1816edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the model column to evaluate\n",
    "model_name_to_evaluate = \"Llama 3.2 3B Instruct Q8\"  # Replace with desired model column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c55e605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pooji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\pooji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\pooji\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\translate\\bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Llama 3.2 3B Instruct Q8\n",
      "                                              Prompt  BLEU   METEOR  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...   0.0  0.06501   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...   0.0  0.12797   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...   0.0  0.06231   \n",
      "\n",
      "   Perplexity  Entropy  \n",
      "0     3.53260  4.31690  \n",
      "1     3.61225  4.29059  \n",
      "2     3.25830  4.39931  \n",
      "\n",
      "Average Perplexity: 3.4677\n",
      "\n",
      "Average Entropy: 4.3356\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Scores\n",
    "results = []\n",
    "for index, row in data.iterrows():\n",
    "    prompt = row[\"Prompt/Model\"]\n",
    "    reference_poem = row[\"Reference Poem\"]\n",
    "    generated_poem = row[model_name_to_evaluate]\n",
    "    \n",
    "    # Calculate scores\n",
    "    bleu = bleu_score(reference_poem, generated_poem)\n",
    "    meteor = meteor_score_func(reference_poem, generated_poem)\n",
    "    perplexity = calculate_perplexity(generated_poem)\n",
    "    entropy = calculate_entropy(generated_poem)\n",
    "    \n",
    "    # Append to results\n",
    "    results.append({\n",
    "        \"Prompt\": prompt,\n",
    "        \"BLEU\": bleu,\n",
    "        \"METEOR\": meteor,\n",
    "        \"Perplexity\": perplexity,\n",
    "        \"Entropy\": entropy  # Fixed key capitalization for clarity\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame for better visualization\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Calculate average entropy\n",
    "average_entropy = results_df[\"Entropy\"].mean()\n",
    "average_perplexity = results_df[\"Perplexity\"].mean()\n",
    "\n",
    "# Add model name to the title\n",
    "evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "\n",
    "# Display Results\n",
    "print(evaluation_title)\n",
    "print(results_df)\n",
    "\n",
    "# Display the average entropy\n",
    "print(f\"\\nAverage Perplexity: {average_perplexity:.4f}\")\n",
    "print(f\"\\nAverage Entropy: {average_entropy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfce078",
   "metadata": {},
   "source": [
    "BLEU: \n",
    "For all three prompts the BLEU score is 0.0, meaning the generated sonnets don't closely match the reference sonnets in terms of exact word sequences. This suggests that the model doesn’t replicate the exact phrases or wording from the reference texts.\n",
    "\n",
    "METEOR:\n",
    "Scores range from approximately 0.062 to 0.127. These low scores indicate that the generated content aligns weakly with the reference, reflecting potential limitations in coherence or content relevancy.\n",
    "\n",
    "Perplexity:\n",
    "Values ranges from 3.25 to 3.61.This means the model is fairly good at predicting the next word, but there is still room for improvement in making the text more fluent and smooth.\n",
    "The average perplexity value of 3.4677 indicates that the model has a relatively low level of uncertainty in predicting the next word, suggesting better fluency and coherence in its generated text. \n",
    "\n",
    "Entropy:\n",
    "Values ranges from 4.31 to 4.39,indicating that the model is producing text with moderate diversity. The average entropy of 4.3356 suggests that the text has a balanced amount of variation, without being overly random or repetitive.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbba43b8",
   "metadata": {},
   "source": [
    "### Diversity and Variety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c7ef8",
   "metadata": {},
   "source": [
    "In the context of poem generation, diversity and variety refer to the richness, uniqueness, and creativity of the generated text, which are critical for producing compelling, engaging, and original poetry.\n",
    "\n",
    "* Self-BLEU : Evaluates how much overlap exists between different samples generated by the same model.\n",
    "* Distinct n-grams: Measures the percentage of distinct n-grams in the generated text compared to the total n-grams. Higher distinctness means more diversity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70e294e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-BLEU Score\n",
    "def self_bleu(generated_texts, n=1):\n",
    "    all_ngrams = []\n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        all_ngrams.append(collections.Counter(ngrams_list))\n",
    "    \n",
    "    # Compute Self-BLEU score\n",
    "    score = 0\n",
    "    for i, counter in enumerate(all_ngrams):\n",
    "        others = all_ngrams[:i] + all_ngrams[i+1:]  # All other generated poems except the current one\n",
    "        union_ngrams = collections.Counter()\n",
    "        for other in others:\n",
    "            union_ngrams.update(other)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if sum(union_ngrams.values()) > 0:\n",
    "            overlap = sum(min(count, union_ngrams[gram]) for gram, count in counter.items())\n",
    "            score += overlap / sum(union_ngrams.values())\n",
    "    \n",
    "    return score / len(generated_texts) if len(generated_texts) > 1 else 0\n",
    "\n",
    "# Distinct-N Score\n",
    "def distinct_n(generated_texts, n=2):\n",
    "    ngrams_set = set()\n",
    "    total_ngrams = 0\n",
    "    \n",
    "    for text in generated_texts:\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)  # Ensure text is a string\n",
    "        tokens = text.split()  # Tokenize text\n",
    "        ngrams_list = list(ngrams(tokens, n))  # Create n-grams\n",
    "        ngrams_set.update(ngrams_list)  # Add n-grams to the set\n",
    "        total_ngrams += len(ngrams_list)\n",
    "    \n",
    "    return len(ngrams_set) / total_ngrams if total_ngrams > 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26b0f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results for Model: Llama 3.2 3B Instruct Q8\n",
      "                      Model  \\\n",
      "0  Llama 3.2 3B Instruct Q8   \n",
      "1  Llama 3.2 3B Instruct Q8   \n",
      "2  Llama 3.2 3B Instruct Q8   \n",
      "\n",
      "                                              Prompt  Self-BLEU (n=1)  \\\n",
      "0  Write a Shakespearean sonnet \\nabout courage s...          0.19815   \n",
      "1  Write a Shakespearean sonnet \\nabout wonder se...          0.19815   \n",
      "2  Write a Shakespearean sonnet \\nabout loss set ...          0.19815   \n",
      "\n",
      "   Distinct-2  \n",
      "0     0.90805  \n",
      "1     0.90805  \n",
      "2     0.90805  \n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate Self-BLEU and Distinct-N for a model\n",
    "def evaluate_model_metrics(data, model_name_to_evaluate):\n",
    "    results = []\n",
    "\n",
    "    # Collect all poems generated by the same model across different prompts\n",
    "    generated_poems = data[model_name_to_evaluate].tolist()\n",
    "\n",
    "    # Calculate Self-BLEU and Distinct-N for the poems generated by the model\n",
    "    self_bleu_score = self_bleu(generated_poems, n=1)  # For unigrams (Self-BLEU n=1)\n",
    "    distinct_2_score = distinct_n(generated_poems, n=2)  # For distinct-2 (bigrams)\n",
    "    \n",
    "    for index, row in data.iterrows():\n",
    "        prompt = row[\"Prompt/Model\"]\n",
    "        \n",
    "        results.append({\n",
    "            \"Model\": model_name_to_evaluate,\n",
    "            \"Prompt\": prompt,\n",
    "            \"Self-BLEU (n=1)\": round(self_bleu_score, 5),\n",
    "            \"Distinct-2\": round(distinct_2_score, 5)\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    evaluation_title = f\"Evaluation Results for Model: {model_name_to_evaluate}\"\n",
    "    \n",
    "    print(evaluation_title)\n",
    "    print(results_df)\n",
    "\n",
    "model_name_to_evaluate = \"Llama 3.2 3B Instruct Q8\" \n",
    "evaluate_model_metrics(data, model_name_to_evaluate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf0fb3e",
   "metadata": {},
   "source": [
    "The model demonstrates strong lexical diversity (as seen with the high Distinct-2 score), suggesting it can generate varied outputs.\n",
    "The relatively low Self-BLEU score implies the model avoids excessive repetition across different prompts, further supporting its ability to generate diverse and contextually distinct text.\n",
    "\n",
    "1.  Self-BLEU : This metric measures the overlap of unigrams (single words) within the text generated by the model for different prompts. A higher Self-BLEU score indicates that the model's outputs are more repetitive or similar across different prompts. In this case, the Self-BLEU value of 0.19815 suggests relatively low similarity, indicating some diversity in the generated outputs.\n",
    "2.  Distinct-2: This metric calculates the ratio of unique bigrams (two-word combinations) to the total number of bigrams in the generated text. It measures lexical diversity, where a higher value signifies more diverse and less repetitive text. Here, the value of 0.90805 indicates a high degree of lexical diversity, meaning the model produces text that is varied and not overly repetitive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a3f659",
   "metadata": {},
   "source": [
    "### Poetic Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10611c9e",
   "metadata": {},
   "source": [
    "The script evaluates the rhyming scheme of the generated poems.\n",
    "\n",
    "* Rhyming Scheme - The rhyming scheme refers to the pattern of rhymes at the end of each line in the poem.\n",
    "* Syllable Count - This step focuses on counting the syllables in each line of the poem. In structured poetry like sonnets, the number of syllables per line is important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b791f339",
   "metadata": {},
   "source": [
    "### Cleaning the sonnet and storing as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7800dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1:\n",
      "  Original Poem: Upon the field of strife, where metal meets,\n",
      "And fierce contention holds its bitter breath,\n",
      "There courage stands, a lion's heart it beats,\n",
      "In soldiers' bosoms, 'gainst all odds they wrench.\n",
      "\n",
      "With every step that falls upon the earth,\n",
      "A resounding echo of resolve doth rise,\n",
      "As brave hearts march to meet their mortal worth,\n",
      "And face the specter of eternity with eyes.\n",
      "\n",
      "Through smoke and fire, through noise and clashing steel,\n",
      "Their unwavering gaze doth pierce the fray,\n",
      "For they fight not for themselves, but for the real,\n",
      "To uphold the virtues that shall never sway.\n",
      "\n",
      "  Processed Lines: ['Upon the field of strife where metal meets', 'And fierce contention holds its bitter breath', 'There courage stands a lions heart it beats', 'In soldiers bosoms gainst all odds they wrench', 'With every step that falls upon the earth', 'A resounding echo of resolve doth rise', 'As brave hearts march to meet their mortal worth', 'And face the specter of eternity with eyes', 'Through smoke and fire through noise and clashing steel', 'Their unwavering gaze doth pierce the fray', 'For they fight not for themselves but for the real', 'To uphold the virtues that shall never sway']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Function to clean and split poems\n",
    "def process_poem(poem):\n",
    "    if isinstance(poem, str):  # Ensure the input is a string\n",
    "        lines = [\n",
    "            line.translate(str.maketrans('', '', string.punctuation))\n",
    "            for line in poem.strip().split('\\n') if line.strip()\n",
    "        ]\n",
    "        return poem, lines\n",
    "    else:\n",
    "        return None, []  # Handle NaN or non-string values\n",
    "\n",
    "\n",
    "# Filter the data for the selected model\n",
    "selected_poems = data[model_name_to_evaluate].head(3)  # Select the first 3 poems for the model\n",
    "\n",
    "# Process the selected poems and assign lines to variables\n",
    "poem1, lines1 = process_poem(selected_poems.iloc[0])\n",
    "poem2, lines2 = process_poem(selected_poems.iloc[1])\n",
    "poem3, lines3 = process_poem(selected_poems.iloc[2])\n",
    "\n",
    "# Print the processed lines for poem1\n",
    "print(\"Poem 1:\")\n",
    "print(f\"  Original Poem: {poem1}\")\n",
    "print(f\"  Processed Lines: {lines1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa4ecfb",
   "metadata": {},
   "source": [
    "### Poetic Structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f85b0d",
   "metadata": {},
   "source": [
    "A Shakespearean Sonnet is a 14 line poem which follows a consitent rhyme scheme pattern of ABAB CDCD EFEF GG and each line is 10 syllables long written in iambic pentameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274169b5",
   "metadata": {},
   "source": [
    "#### Finding the Rhyming Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8ed1aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rhyming Scheme for Poem 1: \n",
      "ABAC\n",
      "DEDE\n",
      "FGFG\n",
      "Rhyming Scheme for Poem 2: \n",
      "ABAB\n",
      "BCBC\n",
      "BDBE\n",
      "FF\n",
      "Rhyming Scheme for Poem 3: \n",
      "ABCD\n",
      "EFGH\n",
      "IJKL\n",
      "MNOP\n",
      "QRSI\n"
     ]
    }
   ],
   "source": [
    "import pronouncing\n",
    "\n",
    "poem_list = [lines1, lines2, lines3]\n",
    "\n",
    "def get_rhyming_scheme(lines):\n",
    "    # Extract the last word of each line\n",
    "    last_words = [line.split()[-1] for line in lines]\n",
    "    rhyme_dict = {}\n",
    "    scheme = []\n",
    "    current_letter = 'A'\n",
    "\n",
    "    for word in last_words:\n",
    "        rhymes = pronouncing.rhymes(word)\n",
    "        # Check if the word rhymes with any previously seen words\n",
    "        for key, letter in rhyme_dict.items():\n",
    "            if word in rhymes or key in rhymes:\n",
    "                scheme.append(letter)\n",
    "                break\n",
    "        else:\n",
    "            # Assign a new letter if no rhyming word is found\n",
    "            rhyme_dict[word] = current_letter\n",
    "            scheme.append(current_letter)\n",
    "            current_letter = chr(ord(current_letter) + 1)\n",
    "\n",
    "    rhyme_scheme = ''.join(scheme)\n",
    "    return '\\n'.join([rhyme_scheme[i:i+4] for i in range(0, len(rhyme_scheme), 4)])\n",
    "\n",
    "\n",
    "# Process each poem and print rhyming schemes\n",
    "for i, poem in enumerate(poem_list, 1):\n",
    "    rhyme_scheme = get_rhyming_scheme(poem)\n",
    "    print(f\"Rhyming Scheme for Poem {i}: \\n{rhyme_scheme}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b259ba",
   "metadata": {},
   "source": [
    "When we compare the rhyming schemes of these poems to a Shakespearean sonnet, we can see clear differences:\n",
    "\n",
    "**Poem 1 (ABAC DEDE FGFG):**  \n",
    "Differs significantly in structure: lacks the Shakespearean alternating rhyme in its stanzas and the concluding couplet. The rhyme scheme alternates inconsistently and does not group into the clear stanzas and couplet structure of a sonnet.\n",
    "\n",
    "**Poem 2 (ABAB BCBC BDBE FF):**  \n",
    "Starts similarly to a Shakespearean sonnet with an alternating ABAB pattern. However, it diverges in the middle with BCBC and BDBE, creating an unusual interlocking structure. Ends with a rhyming couplet (FF), which aligns with the Shakespearean form, but the preceding stanzas are not standard.\n",
    "\n",
    "**Poem 3 (ABCD EFGH IJKL MNOP QRSI):**  \n",
    "Completely diverges from a Shakespearean sonnet's structure. Exhibits no repetition of rhymes or stanzas, with each section introducing entirely new rhymes. The rhyme scheme is non-traditional and lacks the coherence and symmetry of a Shakespearean sonnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e2193",
   "metadata": {},
   "source": [
    "#### Finding the Syllable Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84398be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\pooji\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem 1 syllable counts: [9, 12, 9, 11, 9, 10, 10, 10, 12, 11, 10, 10, 10, 11]\n",
      "Poem 2 syllable counts: [9, 12, 12, 12, 9, 12, 10, 12, 10, 11, 13, 10, 10, 11]\n",
      "Poem 3 syllable counts: [10, 9, 10, 10, 10, 10, 11, 10, 12, 10, 10, 11, 11, 12]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import cmudict\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "nltk.download(\"cmudict\")\n",
    "cmu_dict = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "    \"\"\"\n",
    "    Count syllables for a given word using the CMU Pronouncing Dictionary.\n",
    "    \"\"\"\n",
    "    word = word.lower()\n",
    "    if word in cmu_dict:\n",
    "        return min([len([y for y in x if y[-1].isdigit()]) for x in cmu_dict[word]])\n",
    "    return 1  \n",
    "\n",
    "def analyze_syllable_counts(poem):\n",
    "    \"\"\"\n",
    "    Analyze the syllable count for each line in the poem.\n",
    "    \"\"\"\n",
    "    syllable_counts = [sum(count_syllables(word) for word in re.findall(r'\\w+', line)) for line in poem]\n",
    "    return syllable_counts\n",
    "\n",
    "all_syllable_counts = [analyze_syllable_counts(poem) for poem in poem_list]\n",
    "\n",
    "for idx, syllable_count in enumerate(all_syllable_counts):\n",
    "    print(f\"Poem {idx + 1} syllable counts: {syllable_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6d82f9",
   "metadata": {},
   "source": [
    "Poem 1 :\n",
    "Deviation from Shakespearean sonnet: Poem 1 has an inconsistent syllable count per line, with some lines having fewer or more than the expected 10 syllables. The lines vary between 9 and 12 syllables, creating an irregular rhythm rather than the steady 10-syllable pattern of iambic pentameter.\n",
    "The variations in syllable count also disrupt the traditional flow of a Shakespearean sonnet, which depends on a regular meter to create its musicality.\n",
    "\n",
    "Poem 2 :\n",
    "Deviation from Shakespearean sonnet: Like Poem 1, Poem 2 exhibits variability in syllable counts, with lines ranging from 9 to 13 syllables. Several lines exceed the expected 10 syllables, particularly in the middle of the poem, where there are multiple 12-syllable lines.\n",
    "The lack of consistent 10-syllable lines means the poem doesn't maintain the regular rhythm of iambic pentameter and deviates significantly from the traditional Shakespearean structure.\n",
    "\n",
    "Poem 3 :\n",
    "Deviation from Shakespearean sonnet: Poem 3 starts with a few lines that closely resemble the iambic pentameter structure with 10 syllables per line. However, there are still fluctuations in syllable counts, with lines containing 9, 11 and 12 syllables. This inconsistency affects the rhythm, which would traditionally follow the iambic pentameter pattern.\n",
    "Like the other two poems, this breaks from the expected 10-syllable-per-line structure of a Shakespearean sonnet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
